# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""
Dataloaders and dataset utils
"""

import contextlib
import glob
import hashlib
import json
import math
import os
import random
import shutil
import time
from itertools import repeat
from multiprocessing.pool import Pool, ThreadPool
from pathlib import Path
from threading import Thread
from urllib.parse import urlparse

import numpy as np
import psutil
import torch
import torch.nn.functional as F
import torchvision
import yaml
from PIL import ExifTags, Image, ImageOps
from torch.utils.data import DataLoader, Dataset, dataloader, distributed
from tqdm import tqdm

from utils.augmentations import (Albumentations, augment_hsv, classify_albumentations, classify_transforms, copy_paste,
                                 letterbox, mixup, random_perspective)
from utils.general import (DATASETS_DIR, LOGGER, NUM_THREADS, TQDM_BAR_FORMAT, check_dataset, check_requirements,
                           check_yaml, clean_str, cv2, is_colab, is_kaggle, segments2boxes, unzip_file, xyn2xy,
                           xywh2xyxy, xywhn2xyxy, xyxy2xywhn)
from utils.torch_utils import torch_distributed_zero_first

# Parameters
HELP_URL = 'See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data'
IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # include image suffixes
VID_FORMATS = 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv'  # include video suffixes
LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html
RANK = int(os.getenv('RANK', -1))
PIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders

# ---------------------------------------- 1ã€ç›¸æœºè®¾ç½® ----------------------------------------
# ç›¸æœºè®¾ç½®
# Get orientation exif tag
# ä¸“é—¨ä¸ºæ•°ç ç›¸æœºçš„ç…§ç‰‡è€Œè®¾å®š  å¯ä»¥è®°å½•æ•°ç ç…§ç‰‡çš„å±æ€§ä¿¡æ¯å’Œæ‹æ‘„æ•°æ®
for orientation in ExifTags.TAGS.keys():
    if ExifTags.TAGS[orientation] == 'Orientation':
        break


def get_hash(paths):
    # è¿”å›æ–‡ä»¶åˆ—è¡¨çš„hashå€¼
    # Returns a single hash value of a list of paths (files or dirs)
    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes
    h = hashlib.sha256(str(size).encode())  # hash sizes
    h.update(''.join(paths).encode())  # hash paths
    return h.hexdigest()  # return hash


def exif_size(img):
    # è·å–æ•°ç ç›¸æœºçš„å›¾ç‰‡å®½é«˜ä¿¡æ¯  å¹¶ä¸”åˆ¤æ–­æ˜¯å¦éœ€è¦æ—‹è½¬ï¼ˆæ•°ç ç›¸æœºå¯ä»¥å¤šè§’åº¦æ‹æ‘„ï¼‰
    # Returns exif-corrected PIL size
    s = img.size  # (width, height)
    with contextlib.suppress(Exception):
        rotation = dict(img._getexif().items())[orientation]
        if rotation in [6, 8]:  # rotation 270 or 90
            s = (s[1], s[0])
    return s


def exif_transpose(image):
    """
    Transpose a PIL image accordingly if it has an EXIF Orientation tag.
    Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose()

    :param image: The image to transpose.
    :return: An image.
    """
    exif = image.getexif()
    orientation = exif.get(0x0112, 1)  # default 1
    if orientation > 1:
        method = {
            2: Image.FLIP_LEFT_RIGHT,
            3: Image.ROTATE_180,
            4: Image.FLIP_TOP_BOTTOM,
            5: Image.TRANSPOSE,
            6: Image.ROTATE_270,
            7: Image.TRANSVERSE,
            8: Image.ROTATE_90}.get(orientation)
        if method is not None:
            image = image.transpose(method)
            del exif[0x0112]
            image.info["exif"] = exif.tobytes()
    return image


def seed_worker(worker_id):
    # Set dataloader worker seed https://pytorch.org/docs/stable/notes/randomness.html#dataloader
    worker_seed = torch.initial_seed() % 2 ** 32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


def create_dataloader(path,
                      imgsz,
                      batch_size,
                      stride,
                      single_cls=False,
                      hyp=None,
                      augment=False,
                      cache=False,
                      pad=0.0,
                      rect=False,
                      rank=-1,
                      workers=8,
                      image_weights=False,
                      quad=False,
                      prefix='',
                      shuffle=False,
                      seed=0):
    """åœ¨train.pyä¸­è¢«è°ƒç”¨ï¼Œç”¨äºç”ŸæˆTrainloader, datasetï¼Œtestloader
    è‡ªå®šä¹‰dataloaderå‡½æ•°: è°ƒç”¨LoadImagesAndLabelsè·å–æ•°æ®é›†(åŒ…æ‹¬æ•°æ®å¢å¼º) + è°ƒç”¨åˆ†å¸ƒå¼é‡‡æ ·å™¨DistributedSampler +
                        è‡ªå®šä¹‰InfiniteDataLoader è¿›è¡Œæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    :param path: å›¾ç‰‡æ•°æ®åŠ è½½è·¯å¾„ train/test  å¦‚: ../datasets/VOC/images/train2007
    :param imgsz: train/testå›¾ç‰‡å°ºå¯¸ï¼ˆæ•°æ®å¢å¼ºåå¤§å°ï¼‰ 640
    :param batch_size: batch size å¤§å° 8/16/32
    :param stride: æ¨¡å‹æœ€å¤§stride=32   [32 16 8]
    :param single_cls: æ•°æ®é›†æ˜¯å¦æ˜¯å•ç±»åˆ« é»˜è®¤False
    :param hyp: è¶…å‚åˆ—è¡¨dict ç½‘ç»œè®­ç»ƒæ—¶çš„ä¸€äº›è¶…å‚æ•°ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡ç­‰ï¼Œè¿™é‡Œä¸»è¦ç”¨åˆ°é‡Œé¢ä¸€äº›å…³äºæ•°æ®å¢å¼º(æ—‹è½¬ã€å¹³ç§»ç­‰)çš„ç³»æ•°
    :param augment: æ˜¯å¦è¦è¿›è¡Œæ•°æ®å¢å¼º  True
    :param cache: æ˜¯å¦cache_images False
    :param pad: è®¾ç½®çŸ©å½¢è®­ç»ƒçš„shapeæ—¶è¿›è¡Œçš„å¡«å…… é»˜è®¤0.0
    :param rect: æ˜¯å¦å¼€å¯çŸ©å½¢train/test  é»˜è®¤è®­ç»ƒé›†å…³é—­ éªŒè¯é›†å¼€å¯
    :param rank:  å¤šå¡è®­ç»ƒæ—¶çš„è¿›ç¨‹ç¼–å· rankä¸ºè¿›ç¨‹ç¼–å·  -1ä¸”gpu=1æ—¶ä¸è¿›è¡Œåˆ†å¸ƒå¼  -1ä¸”å¤šå—gpuä½¿ç”¨DataParallelæ¨¡å¼  é»˜è®¤-1
    :param workers: dataloaderçš„numworks åŠ è½½æ•°æ®æ—¶çš„cpuè¿›ç¨‹æ•°
    :param image_weights: è®­ç»ƒæ—¶æ˜¯å¦æ ¹æ®å›¾ç‰‡æ ·æœ¬çœŸå®æ¡†åˆ†å¸ƒæƒé‡æ¥é€‰æ‹©å›¾ç‰‡  é»˜è®¤False
    :param quad: dataloaderå–æ•°æ®æ—¶, æ˜¯å¦ä½¿ç”¨collate_fn4ä»£æ›¿collate_fn  é»˜è®¤False
    :param prefix: æ˜¾ç¤ºä¿¡æ¯   ä¸€ä¸ªæ ‡å¿—ï¼Œå¤šä¸ºtrain/valï¼Œå¤„ç†æ ‡ç­¾æ—¶ä¿å­˜cacheæ–‡ä»¶ä¼šç”¨åˆ°
    """
    if rect and shuffle:
        LOGGER.warning('WARNING âš ï¸ --rect is incompatible with DataLoader shuffle, setting shuffle=False')
        shuffle = False
    # ä¸»è¿›ç¨‹å®ç°æ•°æ®çš„é¢„è¯»å–å¹¶ç¼“å­˜ï¼Œç„¶åå…¶å®ƒå­è¿›ç¨‹åˆ™ä»ç¼“å­˜ä¸­è¯»å–æ•°æ®å¹¶è¿›è¡Œä¸€ç³»åˆ—è¿ç®—ã€‚
    # ä¸ºäº†å®Œæˆæ•°æ®çš„æ­£å¸¸åŒæ­¥, yolov5åŸºäºtorch.distributed.barrier()å‡½æ•°å®ç°äº†ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP
        # è½½å…¥æ–‡ä»¶æ•°æ®(å¢å¼ºæ•°æ®é›†)
        dataset = LoadImagesAndLabels(path, imgsz, batch_size,
                                      augment=augment,  # augmentation
                                      hyp=hyp,  # hyperparameters
                                      rect=rect,  # rectangular batches
                                      cache_images=cache,
                                      single_cls=single_cls,
                                      stride=int(stride),
                                      pad=pad,
                                      image_weights=image_weights,
                                      prefix=prefix)

    batch_size = min(batch_size, len(dataset))
    nd = torch.cuda.device_count()  # number of CUDA devices
    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers
    # åˆ†å¸ƒå¼é‡‡æ ·å™¨DistributedSampler
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    # ä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSampleræ¥å¯¹DataLoaderè¿›è¡Œå°è£…, ä»£æ›¿åŸDå…ˆçš„DataLoader, èƒ½å¤Ÿæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    loader = DataLoader if image_weights else InfiniteDataLoader  # only DataLoader allows for attribute updates
    generator = torch.Generator()
    generator.manual_seed(6148914691236517205 + seed + RANK)
    return loader(dataset,
                  batch_size=batch_size,
                  shuffle=shuffle and sampler is None,
                  num_workers=nw,
                  sampler=sampler,
                  pin_memory=PIN_MEMORY,
                  collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn,
                  worker_init_fn=seed_worker,
                  generator=generator), dataset


class InfiniteDataLoader(dataloader.DataLoader):
    """ Dataloader that reuses workers
    å½“image_weights=Falseæ—¶å°±ä¼šè°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•° è¿›è¡Œè‡ªå®šä¹‰DataLoader
    https://github.com/ultralytics/yolov5/pull/876
    ä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSampleræ¥å¯¹DataLoaderè¿›è¡Œå°è£…, ä»£æ›¿åŸå…ˆçš„DataLoader, èƒ½å¤Ÿæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    Uses same syntax as vanilla DataLoader
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # è°ƒç”¨_RepeatSamplerè¿›è¡ŒæŒç»­é‡‡æ ·
        object.__setattr__(self, 'batch_sampler', _RepeatSampler(self.batch_sampler))
        self.iterator = super().__iter__()

    def __len__(self):
        return len(self.batch_sampler.sampler)

    def __iter__(self):
        for _ in range(len(self)):
            yield next(self.iterator)


class _RepeatSampler:
    """ Sampler that repeats forever
    è¿™éƒ¨åˆ†æ˜¯è¿›è¡ŒæŒç»­é‡‡æ ·
    Args:
        sampler (Sampler)
    """

    def __init__(self, sampler):
        self.sampler = sampler

    def __iter__(self):
        while True:
            yield from iter(self.sampler)


# todo æ–°å¢åŠ çš„æ¨¡å—
class LoadScreenshots:
    # YOLOv5 screenshot dataloader, i.e. `python detect.py --source "screen 0 100 100 512 256"`
    def __init__(self, source, img_size=640, stride=32, auto=True, transforms=None):
        # source = [screen_number left top width height] (pixels)
        check_requirements('mss')
        import mss

        source, *params = source.split()
        self.screen, left, top, width, height = 0, None, None, None, None  # default to full screen 0
        if len(params) == 1:
            self.screen = int(params[0])
        elif len(params) == 4:
            left, top, width, height = (int(x) for x in params)
        elif len(params) == 5:
            self.screen, left, top, width, height = (int(x) for x in params)
        self.img_size = img_size
        self.stride = stride
        self.transforms = transforms
        self.auto = auto
        self.mode = 'stream'
        self.frame = 0
        self.sct = mss.mss()

        # Parse monitor shape
        monitor = self.sct.monitors[self.screen]
        self.top = monitor['top'] if top is None else (monitor['top'] + top)
        self.left = monitor['left'] if left is None else (monitor['left'] + left)
        self.width = width or monitor['width']
        self.height = height or monitor['height']
        self.monitor = {'left': self.left, 'top': self.top, 'width': self.width, 'height': self.height}

    def __iter__(self):
        return self

    def __next__(self):
        # mss screen capture: get raw pixels from the screen as np array
        im0 = np.array(self.sct.grab(self.monitor))[:, :, :3]  # [:, :, :3] BGRA to BGR
        s = f'screen {self.screen} (LTWH): {self.left},{self.top},{self.width},{self.height}: '

        if self.transforms:
            im = self.transforms(im0)  # transforms
        else:
            im = letterbox(im0, self.img_size, stride=self.stride, auto=self.auto)[0]  # padded resize
            im = im.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
            im = np.ascontiguousarray(im)  # contiguous
        self.frame += 1
        return str(self.screen), im, im0, None, s  # screen, img, original img, im0s, s


class LoadImages:
    """åœ¨detect.pyä¸­ä½¿ç”¨
    load æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡/è§†é¢‘
    å®šä¹‰è¿­ä»£å™¨ ç”¨äºdetect.py
    """

    def __init__(self, path, img_size=640, stride=32, auto=True, transforms=None, vid_stride=1):
        if isinstance(path, str) and Path(path).suffix == '.txt':  # *.txt file with img/vid/dir on each line
            path = Path(path).read_text().rsplit()
        files = []
        for p in sorted(path) if isinstance(path, (list, tuple)) else [path]:
            p = str(Path(p).resolve())
            # glob.glab: è¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨   files: æå–å›¾ç‰‡æ‰€æœ‰è·¯å¾„
            if '*' in p:
                # å¦‚æœpæ˜¯é‡‡æ ·æ­£åˆ™åŒ–è¡¨è¾¾å¼æå–å›¾ç‰‡/è§†é¢‘, å¯ä»¥ä½¿ç”¨globè·å–æ–‡ä»¶è·¯å¾„
                files.extend(sorted(glob.glob(p, recursive=True)))  # glob
            elif os.path.isdir(p):
                # å¦‚æœpæ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œä½¿ç”¨globè·å–å…¨éƒ¨æ–‡ä»¶è·¯å¾„
                files.extend(sorted(glob.glob(os.path.join(p, '*.*'))))  # dir
            elif os.path.isfile(p):
                # å¦‚æœpæ˜¯æ–‡ä»¶åˆ™ç›´æ¥è·å–
                files.append(p)  # files
            else:
                raise FileNotFoundError(f'{p} does not exist')

        # images: ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡çš„å›¾ç‰‡å  videos: ç›®å½•ä¸‹æ‰€æœ‰è§†é¢‘çš„è§†é¢‘å
        images = [x for x in files if x.split('.')[-1].lower() in IMG_FORMATS]
        videos = [x for x in files if x.split('.')[-1].lower() in VID_FORMATS]
        # å›¾ç‰‡ä¸è§†é¢‘æ•°é‡
        ni, nv = len(images), len(videos)

        self.img_size = img_size
        self.stride = stride  # æœ€å¤§çš„ä¸‹é‡‡æ ·ç‡
        self.files = images + videos  # æ•´åˆå›¾ç‰‡å’Œè§†é¢‘è·¯å¾„åˆ°ä¸€ä¸ªåˆ—è¡¨
        self.nf = ni + nv  # number of files
        self.video_flag = [False] * ni + [True] * nv  # æ˜¯ä¸æ˜¯video
        self.mode = 'image'
        self.auto = auto
        self.transforms = transforms  # optional
        self.vid_stride = vid_stride  # video frame-rate stride
        if any(videos):
            # åˆ¤æ–­æœ‰æ²¡æœ‰videoæ–‡ä»¶  å¦‚æœåŒ…å«videoæ–‡ä»¶ï¼Œåˆ™åˆå§‹åŒ–opencvä¸­çš„è§†é¢‘æ¨¡å—ï¼Œcap=cv2.VideoCaptureç­‰
            self._new_video(videos[0])  # new video
        else:
            self.cap = None
        assert self.nf > 0, f'No images or videos found in {p}. ' \
                            f'Supported formats are:\nimages: {IMG_FORMATS}\nvideos: {VID_FORMATS}'

    def __iter__(self):
        """è¿­ä»£å™¨"""
        self.count = 0
        return self

    def __next__(self):
        """ä¸iterä¸€èµ·ç”¨ï¼Ÿ"""
        if self.count == self.nf:  # æ•°æ®è¯»å®Œäº†
            raise StopIteration
        path = self.files[self.count]  # è¯»å–å½“å‰æ–‡ä»¶è·¯å¾„

        if self.video_flag[self.count]:  # åˆ¤æ–­å½“å‰æ–‡ä»¶æ˜¯å¦æ˜¯è§†é¢‘
            # Read video
            self.mode = 'video'
            # è·å–å½“å‰å¸§ç”»é¢ï¼Œret_valä¸ºä¸€ä¸ªboolå˜é‡ï¼Œç›´åˆ°è§†é¢‘è¯»å–å®Œæ¯•ä¹‹å‰éƒ½ä¸ºTrue
            for _ in range(self.vid_stride):
                self.cap.grab()

            ret_val, im0 = self.cap.retrieve()
            # å¦‚æœå½“å‰è§†é¢‘è¯»å–ç»“æŸï¼Œåˆ™è¯»å–ä¸‹ä¸€ä¸ªè§†é¢‘
            while not ret_val:
                self.count += 1
                self.cap.release()
                # self.count == self.nfè¡¨ç¤ºè§†é¢‘å·²ç»è¯»å–å®Œäº†
                if self.count == self.nf:  # last video
                    raise StopIteration
                path = self.files[self.count]
                self._new_video(path)
                ret_val, im0 = self.cap.read()

            self.frame += 1  # å½“å‰è¯»å–è§†é¢‘çš„å¸§æ•°
            s = f'video {self.count + 1}/{self.nf} ({self.frame}/{self.frames}) {path}: '

        else:
            # Read image
            self.count += 1
            im0 = cv2.imread(path)  # BGR
            assert im0 is not None, f'Image Not Found {path}'
            s = f'image {self.count}/{self.nf} {path}: '

        if self.transforms:
            im = self.transforms(im0)  # transforms
        else:
            im = letterbox(im0, self.img_size, stride=self.stride, auto=self.auto)[0]  # padded resize
            im = im.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
            im = np.ascontiguousarray(im)  # contiguous

        # è¿”å›è·¯å¾„, resize+padçš„å›¾ç‰‡, åŸå§‹å›¾ç‰‡, è§†é¢‘å¯¹è±¡
        return path, im, im0, self.cap, s

    def _new_video(self, path):
        # è®°å½•å¸§æ•°
        self.frame = 0
        # åˆå§‹åŒ–è§†é¢‘å¯¹è±¡
        self.cap = cv2.VideoCapture(path)
        # å¾—åˆ°è§†é¢‘æ–‡ä»¶ä¸­çš„æ€»å¸§æ•°
        self.frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT) / self.vid_stride)
        self.orientation = int(self.cap.get(cv2.CAP_PROP_ORIENTATION_META))  # rotation degrees
        # self.cap.set(cv2.CAP_PROP_ORIENTATION_AUTO, 0)  # disable https://github.com/ultralytics/yolov5/issues/8493

    def _cv2_rotate(self, im):
        # Rotate a cv2 video manually
        if self.orientation == 0:
            return cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)
        elif self.orientation == 180:
            return cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE)
        elif self.orientation == 90:
            return cv2.rotate(im, cv2.ROTATE_180)
        return im

    def __len__(self):
        return self.nf  # number of files


# ---------------------------------------- 4ã€æ•°æ®é›†æ‰©å±•åŠŸèƒ½ ----------------------------------------
"""
cap.grap():ä»è®¾å¤‡æˆ–è§†é¢‘è·å–ä¸‹ä¸€å¸§,è·å–æˆåŠŸè¿”å›true,æ˜¯å¦ä¸ºfalse
cap.retrieve(frame): åœ¨grapåä½¿ç”¨,å¯¹è·å–åˆ°çš„å¸§è¿›è¡Œè§£ç , ä¹Ÿè¿”å›trueæˆ–false
cap.read(frame): ç»“åˆgrapå’Œretrieveçš„åŠŸèƒ½,æŠ“å–ä¸‹ä¸€å¸§å¹¶è§£ç 
"""


class LoadStreams:
    # YOLOv5 streamloader, i.e. `python detect.py --source 'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP streams`
    """
    load æ–‡ä»¶å¤¹ä¸­è§†é¢‘æµ
    multiple IP or RTSP cameras
    å®šä¹‰è¿­ä»£å™¨ ç”¨äºdetect.py
    """

    def __init__(self, sources='file.streams', img_size=640, stride=32, auto=True, transforms=None, vid_stride=1):
        torch.backends.cudnn.benchmark = True  # faster for fixed-size inference
        self.mode = 'stream'
        self.img_size = img_size
        self.stride = stride
        self.vid_stride = vid_stride  # video frame-rate stride
        sources = Path(sources).read_text().rsplit() if os.path.isfile(sources) else [sources]
        n = len(sources)
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.imgs, self.fps, self.frames, self.threads = [None] * n, [0] * n, [0] * n, [None] * n
        # éå†æ¯ä¸€ä¸ªè§†é¢‘
        for i, s in enumerate(sources):  # index, source
            # Start thread to read frames from video stream
            # æ‰“å°å½“å‰è§†é¢‘index/æ€»è§†é¢‘æ•°/è§†é¢‘æµåœ°å€
            st = f'{i + 1}/{n}: {s}... '
            if urlparse(s).hostname in ('www.youtube.com', 'youtube.com', 'youtu.be'):  # if source is YouTube video
                check_requirements(('pafy', 'youtube_dl==2020.12.2'))
                import pafy
                s = pafy.new(s).getbest(preftype="mp4").url  # YouTube URL
            s = eval(s) if s.isnumeric() else s  # i.e. s = '0' local webcam æœ¬åœ°æ‘„åƒå¤´
            # s='0'æ‰“å¼€æœ¬åœ°æ‘„åƒå¤´ï¼Œå¦åˆ™æ‰“å¼€è§†é¢‘æµåœ°å€
            if s == 0:
                assert not is_colab(), '--source 0 webcam unsupported on Colab. Rerun command in a local environment.'
                assert not is_kaggle(), '--source 0 webcam unsupported on Kaggle. Rerun command in a local environment.'
            cap = cv2.VideoCapture(s)
            assert cap.isOpened(), f'{st}Failed to open {s}'
            # è·å–è§†é¢‘çš„å®½å’Œé•¿
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            # è·å–è§†é¢‘çš„å¸§ç‡
            fps = cap.get(cv2.CAP_PROP_FPS)  # warning: may return 0 or nan
            self.frames[i] = max(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float('inf')  # infinite stream fallback
            self.fps[i] = max((fps if math.isfinite(fps) else 0) % 100, 0) or 30  # 30 FPS fallback

            # è¯»å–å½“å‰ç”»é¢
            _, self.imgs[i] = cap.read()  # guarantee first frame
            # åˆ›å»ºå¤šçº¿ç¨‹è¯»å–è§†é¢‘æµï¼Œdaemonè¡¨ç¤ºä¸»çº¿ç¨‹ç»“æŸæ—¶å­çº¿ç¨‹ä¹Ÿç»“æŸ
            self.threads[i] = Thread(target=self.update, args=([i, cap, s]), daemon=True)
            LOGGER.info(f"{st} Success ({self.frames[i]} frames {w}x{h} at {self.fps[i]:.2f} FPS)")
            self.threads[i].start()
        LOGGER.info('')  # newline

        # check for common shapes
        # è·å–è¿›è¡Œresize+padä¹‹åçš„shapeï¼Œletterboxå‡½æ•°é»˜è®¤(å‚æ•°auto=True)æ˜¯æŒ‰ç…§çŸ©å½¢æ¨ç†è¿›è¡Œå¡«å……
        s = np.stack([letterbox(x, img_size, stride=stride, auto=auto)[0].shape for x in self.imgs])
        self.rect = np.unique(s, axis=0).shape[0] == 1  # rect inference if all shapes equal
        self.auto = auto and self.rect
        self.transforms = transforms  # optional
        if not self.rect:
            LOGGER.warning('WARNING âš ï¸ Stream shapes differ. For optimal performance supply similarly-shaped streams.')

    def update(self, i, cap, stream):
        # Read stream `i` frames in daemon thread
        n, f = 0, self.frames[i]  # frame number, frame array
        while cap.isOpened() and n < f:
            n += 1
            # _, self.imgs[index] = cap.read()
            cap.grab()
            # æ¯readå¸§è¯»å–ä¸€æ¬¡
            if n % self.vid_stride == 0:
                success, im = cap.retrieve()
                if success:
                    self.imgs[i] = im
                else:
                    LOGGER.warning('WARNING âš ï¸ Video stream unresponsive, please check your IP camera connection.')
                    self.imgs[i] = np.zeros_like(self.imgs[i])
                    cap.open(stream)  # re-open stream if signal was lost
            time.sleep(0.0)  # wait time

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        if not all(x.is_alive() for x in self.threads) or cv2.waitKey(1) == ord('q'):  # q to quit
            cv2.destroyAllWindows()
            raise StopIteration

        im0 = self.imgs.copy()
        if self.transforms:
            im = np.stack([self.transforms(x) for x in im0])  # transforms
        else:
            im = np.stack([letterbox(x, self.img_size, stride=self.stride, auto=self.auto)[0] for x in im0])  # resize

            # Convert
            im = im[..., ::-1].transpose((0, 3, 1, 2))  # BGR to RGB, BHWC to BCHW
            im = np.ascontiguousarray(im)  # contiguous è½¬æ¢æˆå†…å­˜è¿ç»­çš„å­˜å‚¨æ–¹å¼

        return self.sources, im, im0, None, ''

    def __len__(self):
        return len(self.sources)  # 1E12 frames = 32 streams at 30 FPS for 30 years


def img2label_paths(img_paths):
    """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__init__å‡½æ•°ä¸­
    æ ¹æ®imgså›¾ç‰‡çš„è·¯å¾„æ‰¾åˆ°å¯¹åº”labelsçš„è·¯å¾„
    Define label paths as a function of image paths
    :params img_paths: {list: 50}  æ•´ä¸ªæ•°æ®é›†çš„å›¾ç‰‡ç›¸å¯¹è·¯å¾„  ä¾‹å¦‚: '..\\datasets\\VOC\\images\\train2007\\000012.jpg'
                                                        =>   '..\\datasets\\VOC\\labels\\train2007\\000012.jpg'
    """
    # å› ä¸ºpythonæ˜¯è·¨å¹³å°çš„,åœ¨Windowsä¸Š,æ–‡ä»¶çš„è·¯å¾„åˆ†éš”ç¬¦æ˜¯'\',åœ¨Linuxä¸Šæ˜¯'/'
    # ä¸ºäº†è®©ä»£ç åœ¨ä¸åŒçš„å¹³å°ä¸Šéƒ½èƒ½è¿è¡Œï¼Œé‚£ä¹ˆè·¯å¾„åº”è¯¥å†™'\'è¿˜æ˜¯'/'å‘¢ï¼Ÿ os.sepæ ¹æ®ä½ æ‰€å¤„çš„å¹³å°, è‡ªåŠ¨é‡‡ç”¨ç›¸åº”çš„åˆ†éš”ç¬¦å·
    # sa: '\\images\\'    sb: '\\labels\\'
    sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels{os.sep}'  # /images/, /labels/ substrings
    # æŠŠimg_pathsä¸­æ‰€ä»¥å›¾ç‰‡è·¯å¾„ä¸­çš„imagesæ›¿æ¢ä¸ºlabels
    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]


# è‡ªå®šä¹‰çš„æ•°æ®é›†
class LoadImagesAndLabels(Dataset):
    # YOLOv5 train_loader/val_loader, loads images and labels for training and validation
    cache_version = 0.6  # dataset labels *.cache version
    rand_interp_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4]

    def __init__(self,
                 path,
                 img_size=640,
                 batch_size=16,
                 augment=False,
                 hyp=None,
                 rect=False,
                 image_weights=False,
                 cache_images=False,
                 single_cls=False,
                 stride=32,
                 pad=0.0,
                 min_items=0,
                 prefix=''):
        self.img_size = img_size
        self.augment = augment
        self.hyp = hyp  # è¶…å‚åˆ—è¡¨
        # å›¾ç‰‡æŒ‰æƒé‡é‡‡æ ·  Trueå°±å¯ä»¥æ ¹æ®ç±»åˆ«é¢‘ç‡(é¢‘ç‡é«˜çš„æƒé‡å°,åæ­£å¤§)æ¥è¿›è¡Œé‡‡æ ·  é»˜è®¤False: ä¸ä½œç±»åˆ«åŒºåˆ†
        self.image_weights = image_weights
        self.rect = False if image_weights else rect  # æ˜¯å¦å¯åŠ¨çŸ©å½¢è®­ç»ƒ ä¸€èˆ¬è®­ç»ƒæ—¶å…³é—­ éªŒè¯æ—¶æ‰“å¼€ å¯ä»¥åŠ é€Ÿ
        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)
        # mosaicå¢å¼ºçš„è¾¹ç•Œå€¼  [-320, -320]
        self.mosaic_border = [-img_size // 2, -img_size // 2]
        self.stride = stride  # æœ€å¤§ä¸‹é‡‡æ ·ç‡ 32
        self.path = path  # å›¾ç‰‡è·¯å¾„
        self.albumentations = Albumentations(size=img_size) if augment else None

        # 2ã€å¾—åˆ°pathè·¯å¾„ä¸‹çš„æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„self.im_files  è¿™é‡Œéœ€è¦è‡ªå·±debugä¸€ä¸‹ ä¸ä¼šå¤ªéš¾
        try:
            f = []  # image files
            for p in path if isinstance(path, list) else [path]:
                # è·å–æ•°æ®é›†è·¯å¾„pathï¼ŒåŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶æˆ–è€…åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
                # ä½¿ç”¨pathlib.Pathç”Ÿæˆä¸æ“ä½œç³»ç»Ÿæ— å…³çš„è·¯å¾„ï¼Œå› ä¸ºä¸åŒæ“ä½œç³»ç»Ÿè·¯å¾„çš„â€˜/â€™ä¼šæœ‰æ‰€ä¸åŒ
                p = Path(p)  # os-agnostic
                # å¦‚æœè·¯å¾„pathä¸ºåŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
                if p.is_dir():  # dir
                    # glob.glab: è¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨  é€’å½’è·å–pè·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶
                    f += glob.glob(str(p / '**' / '*.*'), recursive=True)
                    # f = list(p.rglob('*.*'))  # pathlib
                # å¦‚æœè·¯å¾„pathä¸ºåŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶
                elif p.is_file():  # file
                    with open(p) as t:
                        t = t.read().strip().splitlines()  # è·å–å›¾ç‰‡è·¯å¾„ï¼Œæ›´æ¢ç›¸å¯¹è·¯å¾„
                        # è·å–æ•°æ®é›†è·¯å¾„çš„ä¸Šçº§çˆ¶ç›®å½•  os.sepä¸ºè·¯å¾„é‡Œçš„åˆ†éš”ç¬¦ï¼ˆä¸åŒè·¯å¾„çš„åˆ†éš”ç¬¦ä¸åŒï¼Œos.sepå¯ä»¥æ ¹æ®ç³»ç»Ÿè‡ªé€‚åº”ï¼‰
                        parent = str(p.parent) + os.sep
                        f += [x.replace('./', parent, 1) if x.startswith('./') else x for x in t]  # to global path
                        # f += [p.parent / x.lstrip(os.sep) for x in t]  # to global path (pathlib)
                else:
                    raise FileNotFoundError(f'{prefix}{p} does not exist')
            # ç ´æŠ˜å·æ›¿æ¢ä¸ºos.sepï¼Œos.path.splitext(x)å°†æ–‡ä»¶åä¸æ‰©å±•ååˆ†å¼€å¹¶è¿”å›ä¸€ä¸ªåˆ—è¡¨
            # ç­›é€‰fä¸­æ‰€æœ‰çš„å›¾ç‰‡æ–‡ä»¶
            self.im_files = sorted(x.replace('/', os.sep) for x in f if x.split('.')[-1].lower() in IMG_FORMATS)
            # self.im_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib
            assert self.im_files, f'{prefix}No images found'
        except Exception as e:
            raise Exception(f'{prefix}Error loading data from {path}: {e}\n{HELP_URL}') from e

        # æ ¹æ®imgsè·¯å¾„æ‰¾åˆ°labelsçš„è·¯å¾„self.label_files
        self.label_files = img2label_paths(self.im_files)  # labels
        # cache label ä¸‹æ¬¡è¿è¡Œè¿™ä¸ªè„šæœ¬çš„æ—¶å€™ç›´æ¥ä»cacheä¸­å–labelè€Œä¸æ˜¯å»æ–‡ä»¶ä¸­å–label é€Ÿåº¦æ›´å¿«
        cache_path = (p if p.is_file() else Path(self.label_files[0]).parent).with_suffix('.cache')
        try:
            # å¦‚æœæœ‰cacheæ–‡ä»¶ï¼Œç›´æ¥åŠ è½½  exists=True: æ˜¯å¦å·²ä»cacheæ–‡ä»¶ä¸­è¯»å‡ºäº†nf, nm, ne, nc, nç­‰ä¿¡æ¯
            cache, exists = np.load(cache_path, allow_pickle=True).item(), True  # load dict
            assert cache['version'] == self.cache_version  # same version
            assert cache['hash'] == get_hash(self.label_files + self.im_files)  # same hash
        except Exception:
            # å¦åˆ™è°ƒç”¨cache_labelsç¼“å­˜æ ‡ç­¾åŠæ ‡ç­¾ç›¸å…³ä¿¡æ¯
            cache, exists = self.cache_labels(cache_path, prefix), False  # cache

        # æ‰“å°cacheçš„ç»“æœ nf nm ne nc n = æ‰¾åˆ°çš„æ ‡ç­¾æ•°é‡ï¼Œæ¼æ‰çš„æ ‡ç­¾æ•°é‡ï¼Œç©ºçš„æ ‡ç­¾æ•°é‡ï¼ŒæŸåçš„æ ‡ç­¾æ•°é‡ï¼Œæ€»çš„æ ‡ç­¾æ•°é‡
        nf, nm, ne, nc, n = cache.pop('results')  # found, missing, empty, corrupt, total
        if exists and LOCAL_RANK in {-1, 0}:
            d = f'Scanning {cache_path}... {nf} images, {nm + ne} backgrounds, {nc} corrupt'
            tqdm(None, desc=prefix + d, total=n, initial=n, bar_format=TQDM_BAR_FORMAT)  # display cache results
            if cache['msgs']:
                LOGGER.info('\n'.join(cache['msgs']))  # display warnings
        assert nf > 0 or not augment, f'{prefix}No labels found in {cache_path}, can not start training. {HELP_URL}'

        # 5ã€Read cache  ä»cacheä¸­è¯»å‡ºæœ€æ–°å˜é‡èµ‹ç»™self  æ–¹ä¾¿ç»™forwardä¸­ä½¿ç”¨
        # cacheä¸­çš„é”®å€¼å¯¹æœ€åˆæœ‰: cache[img_file]=[l, shape, segments] cache[hash] cache[results] cache[msg] cache[version]
        # å…ˆä»cacheä¸­å»é™¤cacheæ–‡ä»¶ä¸­å…¶ä»–æ— å…³é”®å€¼å¦‚:'hash', 'version', 'msgs'ç­‰éƒ½åˆ é™¤
        [cache.pop(k) for k in ('hash', 'version', 'msgs')]  # remove items
        # popæ‰resultsã€hashã€versionã€msgsååªå‰©ä¸‹cache[img_file]=[l, shape, segments]
        # cache.values(): å–cacheä¸­æ‰€æœ‰å€¼ å¯¹åº”æ‰€æœ‰l, shape, segments
        # labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
        #         å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
        # shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
        # self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
        #                å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
        # zip æ˜¯å› ä¸ºcacheä¸­æ‰€æœ‰labelsã€shapesã€segmentsä¿¡æ¯éƒ½æ˜¯æŒ‰æ¯å¼ imgåˆ†å¼€å­˜å‚¨çš„, zipæ˜¯å°†æ‰€æœ‰å›¾ç‰‡å¯¹åº”çš„ä¿¡æ¯å åœ¨ä¸€èµ·
        labels, shapes, self.segments = zip(*cache.values())  # segments: éƒ½æ˜¯[]
        nl = len(np.concatenate(labels, 0))  # number of labels
        assert nl > 0 or not augment, f'{prefix}All labels empty in {cache_path}, can not start training. {HELP_URL}'
        self.labels = list(labels)
        self.shapes = np.array(shapes)
        self.im_files = list(cache.keys())  # update
        self.label_files = img2label_paths(cache.keys())  # æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„label_filesä¿¡æ¯(å› ä¸ºimg_filesä¿¡æ¯å¯èƒ½å‘ç”Ÿäº†å˜åŒ–)
        if min_items:
            include = np.array([len(x) >= min_items for x in self.labels]).nonzero()[0].astype(int)
            LOGGER.info(f'{prefix}{n - len(include)}/{n} images filtered from dataset')
            self.im_files = [self.im_files[i] for i in include]
            self.label_files = [self.label_files[i] for i in include]
            self.labels = [self.labels[i] for i in include]
            self.segments = [self.segments[i] for i in include]
            self.shapes = self.shapes[include]  # wh
        n = len(self.shapes)  # number of images
        bi = np.floor(np.arange(n) / batch_size).astype(int)  # batch index
        nb = bi[-1] + 1  # number of batches
        self.batch = bi  # batch index of image
        self.n = n  # number of images
        self.indices = range(n)  # æ‰€æœ‰å›¾ç‰‡çš„index

        # Update labels
        include_class = []  # filter labels to include only these classes (optional)
        self.segments = list(self.segments)
        include_class_array = np.array(include_class).reshape(1, -1)
        for i, (label, segment) in enumerate(zip(self.labels, self.segments)):
            if include_class:
                j = (label[:, 0:1] == include_class_array).any(1)
                self.labels[i] = label[j]
                if segment:
                    self.segments[i] = [segment[idx] for idx, elem in enumerate(j) if elem]
            if single_cls:  # single-class training, merge all classes into 0
                self.labels[i][:, 0] = 0

        # 6ã€ä¸ºRectangular Trainingä½œå‡†å¤‡
        # è¿™é‡Œä¸»è¦æ˜¯æ³¨æ„shapesçš„ç”Ÿæˆ è¿™ä¸€æ­¥å¾ˆé‡è¦ å› ä¸ºå¦‚æœé‡‡æ ·çŸ©å½¢è®­ç»ƒé‚£ä¹ˆæ•´ä¸ªbatchçš„å½¢çŠ¶è¦ä¸€æ · å°±è¦è®¡ç®—è¿™ä¸ªç¬¦åˆæ•´ä¸ªbatchçš„shape
        # è€Œä¸”è¿˜è¦å¯¹æ•°æ®é›†æŒ‰ç…§é«˜å®½æ¯”è¿›è¡Œæ’åº è¿™æ ·æ‰èƒ½ä¿è¯åŒä¸€ä¸ªbatchçš„å›¾ç‰‡çš„å½¢çŠ¶å·®ä¸å¤šç›¸åŒ å†é€‰åˆ™ä¸€ä¸ªå…±åŒçš„shapeä»£ä»·ä¹Ÿæ¯”è¾ƒå°
        if self.rect:
            # Sort by aspect ratio
            s = self.shapes  # wh
            ar = s[:, 1] / s[:, 0]  # aspect ratio
            irect = ar.argsort()  # æ ¹æ®é«˜å®½æ¯”æ’åº
            self.im_files = [self.im_files[i] for i in irect]  # è·å–æ’åºåçš„img_files
            self.label_files = [self.label_files[i] for i in irect]  # è·å–æ’åºåçš„label_files
            self.labels = [self.labels[i] for i in irect]  # è·å–æ’åºåçš„labels
            self.segments = [self.segments[i] for i in irect]
            self.shapes = s[irect]  # è·å–æ’åºåçš„wh
            ar = ar[irect]  # è·å–æ’åºåçš„aspect ratio

            # è®¡ç®—æ¯ä¸ªbatché‡‡ç”¨çš„ç»Ÿä¸€å°ºåº¦ Set training image shapes
            shapes = [[1, 1]] * nb
            for i in range(nb):
                ari = ar[bi == i]  # bi: batch index
                mini, maxi = ari.min(), ari.max()  # è·å–ç¬¬iä¸ªbatchä¸­ï¼Œæœ€å°å’Œæœ€å¤§é«˜å®½æ¯”
                # å¦‚æœé«˜/å®½å°äº1(w > h)ï¼Œå°†wè®¾ä¸ºimg_sizeï¼ˆä¿è¯åŸå›¾åƒå°ºåº¦ä¸å˜è¿›è¡Œç¼©æ”¾ï¼‰
                if maxi < 1:
                    shapes[i] = [maxi, 1]  # maxi: hç›¸å¯¹æŒ‡å®šå°ºåº¦çš„æ¯”ä¾‹  1: wç›¸å¯¹æŒ‡å®šå°ºåº¦çš„æ¯”ä¾‹
                # å¦‚æœé«˜/å®½å¤§äº1(w < h)ï¼Œå°†hè®¾ç½®ä¸ºimg_sizeï¼ˆä¿è¯åŸå›¾åƒå°ºåº¦ä¸å˜è¿›è¡Œç¼©æ”¾ï¼‰
                elif mini > 1:
                    shapes[i] = [1, 1 / mini]

            # è®¡ç®—æ¯ä¸ªbatchè¾“å…¥ç½‘ç»œçš„shapeå€¼(å‘ä¸Šè®¾ç½®ä¸º32çš„æ•´æ•°å€)
            # è¦æ±‚æ¯ä¸ªbatch_shapesçš„é«˜å®½éƒ½æ˜¯32çš„æ•´æ•°å€ï¼Œæ‰€ä»¥è¦å…ˆé™¤ä»¥32ï¼Œå–æ•´å†ä¹˜ä»¥32ï¼ˆä¸è¿‡img_sizeå¦‚æœæ˜¯32å€æ•°è¿™é‡Œå°±æ²¡å¿…è¦äº†ï¼‰
            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(int) * stride

        # 7ã€æ˜¯å¦éœ€è¦cache image ä¸€èˆ¬æ˜¯False å› ä¸ºRAMä¼šä¸è¶³  cache labelè¿˜å¯ä»¥ ä½†æ˜¯cache imageå°±å¤ªå¤§äº† æ‰€ä»¥ä¸€èˆ¬ä¸ç”¨
        # Cache images into RAM/disk for faster training (WARNING: large datasets may exceed system resources)
        if cache_images == 'ram' and not self.check_cache_ram(prefix=prefix):
            cache_images = False
        self.ims = [None] * n
        self.npy_files = [Path(f).with_suffix('.npy') for f in self.im_files]
        if cache_images:
            b, gb = 0, 1 << 30  # bytes of cached images, bytes per gigabytes
            self.im_hw0, self.im_hw = [None] * n, [None] * n
            fcn = self.cache_images_to_disk if cache_images == 'disk' else self.load_image
            results = ThreadPool(NUM_THREADS).imap(fcn, range(n))
            pbar = tqdm(enumerate(results), total=n, bar_format=TQDM_BAR_FORMAT, disable=LOCAL_RANK > 0)
            for i, x in pbar:
                if cache_images == 'disk':
                    b += self.npy_files[i].stat().st_size
                else:  # 'ram'
                    self.ims[i], self.im_hw0[i], self.im_hw[i] = x  # im, hw_orig, hw_resized = load_image(self, i)
                    b += self.ims[i].nbytes
                pbar.desc = f'{prefix}Caching images ({b / gb:.1f}GB {cache_images})'
            pbar.close()

    def check_cache_ram(self, safety_margin=0.1, prefix=''):
        # Check image caching requirements vs available memory
        b, gb = 0, 1 << 30  # bytes of cached images, bytes per gigabytes
        n = min(self.n, 30)  # extrapolate from 30 random images
        for _ in range(n):
            im = cv2.imread(random.choice(self.im_files))  # sample image
            ratio = self.img_size / max(im.shape[0], im.shape[1])  # max(h, w)  # ratio
            b += im.nbytes * ratio ** 2
        mem_required = b * self.n / n  # GB required to cache dataset into RAM
        mem = psutil.virtual_memory()
        cache = mem_required * (1 + safety_margin) < mem.available  # to cache or not to cache, that is the question
        if not cache:
            LOGGER.info(f'{prefix}{mem_required / gb:.1f}GB RAM required, '
                        f'{mem.available / gb:.1f}/{mem.total / gb:.1f}GB available, '
                        f"{'caching images âœ…' if cache else 'not caching images âš ï¸'}")
        return cache

    def cache_labels(self, path=Path('./labels.cache'), prefix=''):
        """ç”¨åœ¨__init__å‡½æ•°ä¸­  cacheæ•°æ®é›†label
        åŠ è½½labelä¿¡æ¯ç”Ÿæˆcacheæ–‡ä»¶   Cache dataset labels, check images and read shapes
        :params path: cacheæ–‡ä»¶ä¿å­˜åœ°å€
        :params prefix: æ—¥å¿—å¤´éƒ¨ä¿¡æ¯(å½©æ‰“é«˜äº®éƒ¨åˆ†)
        :return x: cacheä¸­ä¿å­˜çš„å­—å…¸
               åŒ…æ‹¬çš„ä¿¡æ¯æœ‰: x[im_file] = [l, shape, segments]
                          ä¸€å¼ å›¾ç‰‡ä¸€ä¸ªlabelç›¸å¯¹åº”çš„ä¿å­˜åˆ°x, æœ€ç»ˆxä¼šä¿å­˜æ‰€æœ‰å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„ã€gtæ¡†çš„ä¿¡æ¯ã€å½¢çŠ¶shapeã€æ‰€æœ‰çš„å¤šè¾¹å½¢gtä¿¡æ¯
                              im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
                              l: å½“å‰è¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(ä¸åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, cls+xywh(normalized)]
                              shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
                              segments: å½“å‰è¿™å¼ å›¾ç‰‡æ‰€æœ‰gtçš„labelä¿¡æ¯(åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
                           hash: å½“å‰å›¾ç‰‡å’Œlabelæ–‡ä»¶çš„hashå€¼  1
                           results: æ‰¾åˆ°çš„labelä¸ªæ•°nf, ä¸¢å¤±labelä¸ªæ•°nm, ç©ºlabelä¸ªæ•°ne, ç ´æŸlabelä¸ªæ•°nc, æ€»img/labelä¸ªæ•°len(self.im_files)
                           msgs: æ‰€æœ‰æ•°æ®é›†çš„msgsä¿¡æ¯
                           version: å½“å‰cache version
        """
        x = {}  # åˆå§‹åŒ–æœ€ç»ˆcacheä¸­ä¿å­˜çš„å­—å…¸dict
        # åˆå§‹åŒ–number missing, found, empty, corrupt, messages
        # åˆå§‹åŒ–æ•´ä¸ªæ•°æ®é›†: æ¼æ‰çš„æ ‡ç­¾(label)æ€»æ•°é‡, æ‰¾åˆ°çš„æ ‡ç­¾(label)æ€»æ•°é‡, ç©ºçš„æ ‡ç­¾(label)æ€»æ•°é‡, é”™è¯¯æ ‡ç­¾(label)æ€»æ•°é‡, æ‰€æœ‰é”™è¯¯ä¿¡æ¯
        nm, nf, ne, nc, msgs = 0, 0, 0, 0, []  # number missing, found, empty, corrupt, messages
        desc = f'{prefix}Scanning {path.parent / path.stem}...'
        # å¤šè¿›ç¨‹è°ƒç”¨verify_image_labelå‡½æ•°
        with Pool(NUM_THREADS) as pool:
            # å®šä¹‰pbarè¿›åº¦æ¡
            # pool.imap_unordered: å¯¹å¤§é‡æ•°æ®éå†å¤šè¿›ç¨‹è®¡ç®— è¿”å›ä¸€ä¸ªè¿­ä»£å™¨
            # æŠŠself.im_files, self.label_files, repeat(prefix) listä¸­çš„å€¼ä½œä¸ºå‚æ•°ä¾æ¬¡é€å…¥(ä¸€æ¬¡é€ä¸€ä¸ª)verify_image_labelå‡½æ•°
            pbar = tqdm(pool.imap(verify_image_label, zip(self.im_files, self.label_files, repeat(prefix))),
                        desc=desc,
                        total=len(self.im_files),
                        bar_format=TQDM_BAR_FORMAT)
            # l: [gt_num, cls+xywh(normalized)]
            #    å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ lå°±å­˜å‚¨åŸlabel(å…¨éƒ¨æ˜¯æ­£å¸¸çŸ©å½¢æ ‡ç­¾)
            #    å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾  lå°±å­˜å‚¨ç»è¿‡segments2boxeså¤„ç†å¥½çš„æ ‡ç­¾(æ­£å¸¸çŸ©å½¢æ ‡ç­¾ä¸å¤„ç† å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºçŸ©å½¢æ ‡ç­¾)
            # shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
            # segments: å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å­˜å‚¨None
            #           å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å°±æŠŠè¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰labelå­˜å‚¨åˆ°segmentsä¸­(è‹¥å¹²ä¸ªæ­£å¸¸gt è‹¥å¹²ä¸ªå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
            # nm_f(nm): number missing å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦ä¸¢å¤±         ä¸¢å¤±=1    å­˜åœ¨=0
            # nf_f(nf): number found å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦å­˜åœ¨           å­˜åœ¨=1    ä¸¢å¤±=0
            # ne_f(ne): number empty å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦æ˜¯ç©ºçš„         ç©ºçš„=1    æ²¡ç©º=0
            # nc_f(nc): number corrupt å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ–‡ä»¶æ˜¯å¦æ˜¯ç ´æŸçš„  ç ´æŸçš„=1  æ²¡ç ´æŸ=0
            # msg: è¿”å›çš„msgä¿¡æ¯  labelæ–‡ä»¶å®Œå¥½=â€˜â€™  labelæ–‡ä»¶ç ´æŸ=warningä¿¡æ¯
            for im_file, lb, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:
                nm += nm_f  # ç´¯åŠ æ€»number missing label
                nf += nf_f  # ç´¯åŠ æ€»number found label
                ne += ne_f  # ç´¯åŠ æ€»number empty label
                nc += nc_f  # ç´¯åŠ æ€»number corrupt label
                if im_file:
                    x[im_file] = [lb, shape, segments]
                if msg:
                    msgs.append(msg)  # å°†msgåŠ å…¥æ€»msg
                pbar.desc = f'{desc} {nf} images, {nm + ne} backgrounds, {nc} corrupt'

        pbar.close()  # å…³é—­è¿›åº¦æ¡
        # æ—¥å¿—æ‰“å°æ‰€æœ‰msgä¿¡æ¯
        if msgs:
            LOGGER.info('\n'.join(msgs))
        if nf == 0:
            LOGGER.warning(f'{prefix}WARNING âš ï¸ No labels found in {path}. {HELP_URL}')
        x['hash'] = get_hash(self.label_files + self.im_files)  # å°†å½“å‰å›¾ç‰‡å’Œlabelæ–‡ä»¶çš„hashå€¼å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['results'] = nf, nm, ne, nc, len(self.im_files)  # å°†nf, nm, ne, nc, len(self.im_files)å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['msgs'] = msgs  # å°†æ‰€æœ‰æ•°æ®é›†çš„msgsä¿¡æ¯å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['version'] = self.cache_version  # å°†å½“å‰cache versionå­˜å…¥æœ€ç»ˆå­—å…¸dist
        try:
            np.save(path, x)  # save cache for next time
            path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix
            LOGGER.info(f'{prefix}New cache created: {path}')
        except Exception as e:
            LOGGER.warning(f'{prefix}WARNING âš ï¸ Cache directory {path.parent} is not writeable: {e}')  # not writeable
        return x

    def __len__(self):
        return len(self.im_files)

    # def __iter__(self):
    #     self.count = -1
    #     print('ran dataset iter')
    #     #self.shuffled_vector = np.random.permutation(self.nF) if self.augment else np.arange(self.nF)
    #     return self

    def __getitem__(self, index):
        """
        è¿™éƒ¨åˆ†æ˜¯æ•°æ®å¢å¼ºå‡½æ•°ï¼Œä¸€èˆ¬ä¸€æ¬¡æ€§æ‰§è¡Œbatch_sizeæ¬¡ã€‚
        è®­ç»ƒ æ•°æ®å¢å¼º: mosaic(random_perspective) + hsv + ä¸Šä¸‹å·¦å³ç¿»è½¬
        æµ‹è¯• æ•°æ®å¢å¼º: letterbox
        :return torch.from_numpy(img): è¿™ä¸ªindexçš„å›¾ç‰‡æ•°æ®(å¢å¼ºå) [3, 640, 640]
        :return labels_out: è¿™ä¸ªindexå›¾ç‰‡çš„gt label [6, 6] = [gt_num, 0+class+xywh(normalized)]
        :return self.im_files[index]: è¿™ä¸ªindexå›¾ç‰‡çš„è·¯å¾„åœ°å€
        :return shapes: è¿™ä¸ªbatchçš„å›¾ç‰‡çš„shapes æµ‹è¯•æ—¶(çŸ©å½¢è®­ç»ƒ)æ‰æœ‰  éªŒè¯æ—¶ä¸ºNone   for COCO mAP rescaling
        """
        # è¿™é‡Œå¯ä»¥é€šè¿‡ä¸‰ç§å½¢å¼è·å–è¦è¿›è¡Œæ•°æ®å¢å¼ºçš„å›¾ç‰‡index  linear, shuffled, or image_weights
        index = self.indices[index]  # linear, shuffled, or image_weights

        hyp = self.hyp  # è¶…å‚ åŒ…å«ä¼—å¤šæ•°æ®å¢å¼ºè¶…å‚
        mosaic = self.mosaic and random.random() < hyp['mosaic']
        # mosaicå¢å¼º å¯¹å›¾åƒè¿›è¡Œ4å¼ å›¾æ‹¼æ¥è®­ç»ƒ  ä¸€èˆ¬è®­ç»ƒæ—¶è¿è¡Œ
        # mosaic + MixUp
        if mosaic:
            # Load mosaic
            img, labels = self.load_mosaic(index)
            shapes = None

            # MixUp augmentation
            if random.random() < hyp['mixup']:
                # *load_mosaic(self, random.randint(0, self.n - 1)) éšæœºä»æ•°æ®é›†ä¸­ä»»é€‰ä¸€å¼ å›¾ç‰‡å’Œæœ¬å¼ å›¾ç‰‡è¿›è¡Œmixupæ•°æ®å¢å¼º
                # img:   ä¸¤å¼ å›¾ç‰‡èåˆä¹‹åçš„å›¾ç‰‡ numpy (640, 640, 3)
                # labels: ä¸¤å¼ å›¾ç‰‡èåˆä¹‹åçš„æ ‡ç­¾label [M+N, cls+x1y1x2y2]
                img, labels = mixup(img, labels, *self.load_mosaic(random.randint(0, self.n - 1)))

        else:
            # Load image
            # è½½å…¥å›¾ç‰‡  è½½å…¥å›¾ç‰‡åè¿˜ä¼šè¿›è¡Œä¸€æ¬¡resize  å°†å½“å‰å›¾ç‰‡çš„æœ€é•¿è¾¹ç¼©æ”¾åˆ°æŒ‡å®šçš„å¤§å°(512), è¾ƒå°è¾¹åŒæ¯”ä¾‹ç¼©æ”¾
            # load image img=(343, 512, 3)=(h, w, c)  (h0, w0)=(335, 500)  numpy  index=4
            # img: resizeåçš„å›¾ç‰‡   (h0, w0): åŸå§‹å›¾ç‰‡çš„hw  (h, w): resizeåçš„å›¾ç‰‡çš„hw
            # è¿™ä¸€æ­¥æ˜¯å°†(335, 500, 3) resize-> (343, 512, 3)
            img, (h0, w0), (h, w) = self.load_image(index)

            # Letterbox
            # letterboxä¹‹å‰ç¡®å®šè¿™å¼ å½“å‰å›¾ç‰‡letterboxä¹‹åçš„shape  å¦‚æœä¸ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯self.img_size
            # å¦‚æœä½¿ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯å½“å‰batchçš„shape å› ä¸ºçŸ©å½¢è®­ç»ƒçš„è¯æˆ‘ä»¬æ•´ä¸ªbatchçš„shapeå¿…é¡»ç»Ÿä¸€(åœ¨__init__å‡½æ•°ç¬¬6èŠ‚å†…å®¹)
            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape
            # letterbox è¿™ä¸€æ­¥å°†ç¬¬ä¸€æ­¥ç¼©æ”¾å¾—åˆ°çš„å›¾ç‰‡å†ç¼©æ”¾åˆ°å½“å‰batchæ‰€éœ€è¦çš„å°ºåº¦ (343, 512, 3) pad-> (384, 512, 3)
            # (çŸ©å½¢æ¨ç†éœ€è¦ä¸€ä¸ªbatchçš„æ‰€æœ‰å›¾ç‰‡çš„shapeå¿…é¡»ç›¸åŒï¼Œè€Œè¿™ä¸ªshapeåœ¨initå‡½æ•°ä¸­ä¿æŒåœ¨self.batch_shapesä¸­)
            # è¿™é‡Œæ²¡æœ‰ç¼©æ”¾æ“ä½œï¼Œæ‰€ä»¥è¿™é‡Œçš„ratioæ°¸è¿œéƒ½æ˜¯(1.0, 1.0)  pad=(0.0, 20.5)
            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)
            shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling

            # å›¾ç‰‡letterboxä¹‹ålabelçš„åæ ‡ä¹Ÿè¦ç›¸åº”å˜åŒ–  æ ¹æ®padè°ƒæ•´labelåæ ‡ å¹¶å°†å½’ä¸€åŒ–çš„xywh -> æœªå½’ä¸€åŒ–çš„xyxy
            labels = self.labels[index].copy()
            if labels.size:  # normalized xywh to pixel xyxy format
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])

            if self.augment:
                img, labels = random_perspective(img,
                                                 labels,
                                                 degrees=hyp['degrees'],
                                                 translate=hyp['translate'],
                                                 scale=hyp['scale'],
                                                 shear=hyp['shear'],
                                                 perspective=hyp['perspective'])

        nl = len(labels)  # number of labels
        if nl:
            labels[:, 1:5] = xyxy2xywhn(labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=True, eps=1E-3)

        if self.augment:
            # Albumentations
            img, labels = self.albumentations(img, labels)
            nl = len(labels)  # update after albumentations

            # HSV color-space
            augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])

            # éšæœºä¸Šä¸‹ç¿»è½¬ flip up-down
            if random.random() < hyp['flipud']:
                img = np.flipud(img)  # np.flipud å°†æ•°ç»„åœ¨ä¸Šä¸‹æ–¹å‘ç¿»è½¬ã€‚
                if nl:
                    labels[:, 2] = 1 - labels[:, 2]  # 1 - y_center  labelä¹Ÿè¦æ˜ å°„

            # éšæœºå·¦å³ç¿»è½¬ flip left-right
            if random.random() < hyp['fliplr']:
                img = np.fliplr(img)  # np.fliplr å°†æ•°ç»„åœ¨å·¦å³æ–¹å‘ç¿»è½¬
                if nl:
                    labels[:, 1] = 1 - labels[:, 1]  # 1 - x_center  labelä¹Ÿè¦æ˜ å°„

            # Cutouts
            # labels = cutout(img, labels, p=0.5)
            # nl = len(labels)  # update after cutout

        labels_out = torch.zeros((nl, 6))
        if nl:
            labels_out[:, 1:] = torch.from_numpy(labels)

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)  # imgå˜æˆå†…å­˜è¿ç»­çš„æ•°æ®  åŠ å¿«è¿ç®—

        return torch.from_numpy(img), labels_out, self.im_files[index], shapes

    def load_image(self, i):
        """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•°å’Œload_mosaicæ¨¡å—ä¸­
        ä»selfæˆ–è€…ä»å¯¹åº”å›¾ç‰‡è·¯å¾„ä¸­è½½å…¥å¯¹åº”indexçš„å›¾ç‰‡ å¹¶å°†åŸå›¾ä¸­hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•
            loads 1 image from dataset, returns img, original hw, resized hw
        :params self: ä¸€èˆ¬æ˜¯å¯¼å…¥LoadImagesAndLabelsä¸­çš„self
        :param index: å½“å‰å›¾ç‰‡çš„index
        :return: img: resizeåçš„å›¾ç‰‡
                (h0, w0): hw_original  åŸå›¾çš„hw
                img.shape[:2]: hw_resized resizeåçš„å›¾ç‰‡hw(hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•)
        """
        # Loads 1 image from dataset index 'i', returns (im, original hw, resized hw)
        # æŒ‰indexä»self.imgsä¸­è½½å…¥å½“å‰å›¾ç‰‡, ä½†æ˜¯ç”±äºç¼“å­˜çš„å†…å®¹ä¸€èˆ¬ä¼šä¸å¤Ÿ, æ‰€ä»¥æˆ‘ä»¬ä¸€èˆ¬ä¸ä¼šç”¨self.imgs(cache)ä¿å­˜æ‰€æœ‰çš„å›¾ç‰‡
        im, f, fn = self.ims[i], self.im_files[i], self.npy_files[i],
        if im is None:  # å›¾ç‰‡æ˜¯ç©ºçš„è¯, å°±ä»å¯¹åº”æ–‡ä»¶è·¯å¾„è¯»å‡ºè¿™å¼ å›¾ç‰‡
            if fn.exists():  # load npy
                im = np.load(fn)
            else:  # read image
                im = cv2.imread(f)  # BGR
                assert im is not None, f'Image Not Found {f}'
            h0, w0 = im.shape[:2]  # orig hw
            # img_size è®¾ç½®çš„æ˜¯é¢„å¤„ç†åè¾“å‡ºçš„å›¾ç‰‡å°ºå¯¸   r=ç¼©æ”¾æ¯”ä¾‹
            r = self.img_size / max(h0, w0)  # ratio
            # æ ¹æ®ratioé€‰æ‹©ä¸åŒçš„å·®å€¼æ–¹å¼
            if r != 1:  # if sizes are not equal
                # cv2.INTER_AREA: åŸºäºåŒºåŸŸåƒç´ å…³ç³»çš„ä¸€ç§é‡é‡‡æ ·æˆ–è€…æ’å€¼æ–¹å¼.è¯¥æ–¹æ³•æ˜¯å›¾åƒæŠ½å–çš„é¦–é€‰æ–¹æ³•, å®ƒå¯ä»¥äº§ç”Ÿæ›´å°‘çš„æ³¢çº¹
                # cv2.INTER_LINEAR: åŒçº¿æ€§æ’å€¼,é»˜è®¤æƒ…å†µä¸‹ä½¿ç”¨è¯¥æ–¹å¼è¿›è¡Œæ’å€¼   æ ¹æ®ratioé€‰æ‹©ä¸åŒçš„æ’å€¼æ–¹å¼
                # å°†åŸå›¾ä¸­hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•
                interp = cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA
                im = cv2.resize(im, (math.ceil(w0 * r), math.ceil(h0 * r)), interpolation=interp)
            return im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized
        return self.ims[i], self.im_hw0[i], self.im_hw[i]  # im, hw_original, hw_resized

    def cache_images_to_disk(self, i):
        # Saves an image as an *.npy file for faster loading
        f = self.npy_files[i]
        if not f.exists():
            np.save(f.as_posix(), cv2.imread(self.im_files[i]))

    def load_mosaic(self, index):
        """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•° è¿›è¡Œmosaicæ•°æ®å¢å¼º
        å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­  loads images in a 4-mosaic
        :param index: éœ€è¦è·å–çš„å›¾åƒç´¢å¼•
        :return: img4: mosaicå’Œéšæœºé€è§†å˜æ¢åçš„ä¸€å¼ å›¾ç‰‡  numpy(640, 640, 3)
                 labels4: img4å¯¹åº”çš„target  [M, cls+x1y1x2y2]
        """
        # labels4: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ4å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(ä¸åŒ…å«segmentså¤šè¾¹å½¢)
        # segments4: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ4å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢)
        labels4, segments4 = [], []
        s = self.img_size  # ä¸€èˆ¬çš„å›¾ç‰‡å¤§å°
        # éšæœºåˆå§‹åŒ–æ‹¼æ¥å›¾åƒçš„ä¸­å¿ƒç‚¹åæ ‡  [0, s*2]ä¹‹é—´éšæœºå–2ä¸ªæ•°ä½œä¸ºæ‹¼æ¥å›¾åƒçš„ä¸­å¿ƒåæ ‡
        yc, xc = (int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border)  # mosaic center x, y
        # ä»datasetä¸­éšæœºå¯»æ‰¾é¢å¤–çš„ä¸‰å¼ å›¾åƒè¿›è¡Œæ‹¼æ¥ [14, 26, 2, 16] å†éšæœºé€‰ä¸‰å¼ å›¾ç‰‡çš„index
        indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices
        random.shuffle(indices)
        for i, index in enumerate(indices):
            # load image   æ¯æ¬¡æ‹¿ä¸€å¼ å›¾ç‰‡ å¹¶å°†è¿™å¼ å›¾ç‰‡resizeåˆ°self.size(h,w)
            img, _, (h, w) = self.load_image(index)

            # place img in img4
            if i == 0:  # top left
                # åˆ›å»ºé©¬èµ›å…‹å›¾åƒ [1472, 1472, 3]=[h, w, c]
                img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
                # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)   w=736  h = 552  é©¬èµ›å…‹å›¾åƒï¼š(x1a,y1a)å·¦ä¸Šè§’ (x2a,y2a)å³ä¸‹è§’
                x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)
                # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬ä¸€å¼ å›¾åƒçš„å³ä¸‹è§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)  å›¾åƒï¼š(x1b,y1b)å·¦ä¸Šè§’ (x2b,y2b)å³ä¸‹è§’
                x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)
            elif i == 1:  # top right
                # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
                x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc
                # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬äºŒå¼ å›¾åƒçš„å·¦ä¸‹è§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
                x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h
            elif i == 2:  # bottom left
                # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
                x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)
                # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬ä¸‰å¼ å›¾åƒçš„å³ä¸Šè§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
                x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)
            elif i == 3:  # bottom right
                # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
                x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)
                # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬å››å¼ å›¾åƒçš„å·¦ä¸Šè§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
                x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)

            # å°†æˆªå–çš„å›¾åƒåŒºåŸŸå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒçš„ç›¸åº”ä½ç½®   img4[h, w, c]
            # å°†å›¾åƒimgçš„ã€(x1b,y1b)å·¦ä¸Šè§’ (x2b,y2b)å³ä¸‹è§’ã€‘åŒºåŸŸæˆªå–å‡ºæ¥å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒçš„ã€(x1a,y1a)å·¦ä¸Šè§’ (x2a,y2a)å³ä¸‹è§’ã€‘åŒºåŸŸ
            img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
            # è®¡ç®—pad(å½“å‰å›¾åƒè¾¹ç•Œä¸é©¬èµ›å…‹è¾¹ç•Œçš„è·ç¦»ï¼Œè¶Šç•Œçš„æƒ…å†µpadw/padhä¸ºè´Ÿå€¼)  ç”¨äºåé¢çš„labelæ˜ å°„
            padw = x1a - x1b  # å½“å‰å›¾åƒä¸é©¬èµ›å…‹å›¾åƒåœ¨wç»´åº¦ä¸Šç›¸å·®å¤šå°‘
            padh = y1a - y1b  # å½“å‰å›¾åƒä¸é©¬èµ›å…‹å›¾åƒåœ¨hç»´åº¦ä¸Šç›¸å·®å¤šå°‘

            # labels: è·å–å¯¹åº”æ‹¼æ¥å›¾åƒçš„æ‰€æœ‰æ­£å¸¸labelä¿¡æ¯(å¦‚æœæœ‰segmentså¤šè¾¹å½¢ä¼šè¢«è½¬åŒ–ä¸ºçŸ©å½¢label)
            # segments: è·å–å¯¹åº”æ‹¼æ¥å›¾åƒçš„æ‰€æœ‰ä¸æ­£å¸¸labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢ä¹ŸåŒ…å«æ­£å¸¸gt)
            labels, segments = self.labels[index].copy(), self.segments[index].copy()
            if labels.size:
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padw, padh)  # normalized xywh to pixel xyxy format
                segments = [xyn2xy(x, w, h, padw, padh) for x in segments]
            labels4.append(labels)  # æ›´æ–°labels4
            segments4.extend(segments)  # æ›´æ–°segments4

        # Concat/clip labels
        labels4 = np.concatenate(labels4, 0)
        # é˜²æ­¢è¶Šç•Œ  label[:, 1:]ä¸­çš„æ‰€æœ‰å…ƒç´ çš„å€¼ï¼ˆä½ç½®ä¿¡æ¯ï¼‰å¿…é¡»åœ¨[0, 2*s]ä¹‹é—´,å°äº0å°±ä»¤å…¶ç­‰äº0,å¤§äº2*så°±ç­‰äº2*s   out: è¿”å›
        for x in (labels4[:, 1:], *segments4):
            np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
        # img4, labels4 = replicate(img4, labels4)  # replicate

        # Augment
        img4, labels4, segments4 = copy_paste(img4, labels4, segments4, p=self.hyp['copy_paste'])
        # è¿›è¡Œmosaicçš„æ—¶å€™å°†å››å¼ å›¾ç‰‡æ•´åˆåˆ°ä¸€èµ·æŒ‡æŒ¥shapeä¸º[2*img_size,2*img_size]
        # å¯¹mosaicæ•´åˆçš„å›¾ç‰‡è¿›è¡Œéšæœºæ—‹è½¬ï¼Œå¹³ç§»ï¼Œç¼©æ”¾ï¼Œè£å‰ªï¼Œå¹¶resizeä¸ºè¾“å…¥å¤§å°img_size
        img4, labels4 = random_perspective(img4,
                                           labels4,
                                           segments4,
                                           degrees=self.hyp['degrees'],
                                           translate=self.hyp['translate'],
                                           scale=self.hyp['scale'],
                                           shear=self.hyp['shear'],
                                           perspective=self.hyp['perspective'],
                                           border=self.mosaic_border)  # border to remove

        return img4, labels4

    def load_mosaic9(self, index):
        """ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•° æ›¿æ¢mosaicæ•°æ®å¢å¼º
        å°†ä¹å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­  loads images in a 9-mosaic
        :param self:
        :param index: éœ€è¦è·å–çš„å›¾åƒç´¢å¼•
        :return: img9: mosaicå’Œä»¿å°„å¢å¼ºåçš„ä¸€å¼ å›¾ç‰‡
                 labels9: img9å¯¹åº”çš„target
        """
        # labels9: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ9å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(ä¸åŒ…å«segmentså¤šè¾¹å½¢)
        # segments9: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ9å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢)
        labels9, segments9 = [], []
        s = self.img_size  # ä¸€èˆ¬çš„å›¾ç‰‡å¤§å°(ä¹Ÿæ˜¯æœ€ç»ˆè¾“å‡ºçš„å›¾ç‰‡å¤§å°)
        # ä»datasetä¸­éšæœºå¯»æ‰¾é¢å¤–çš„ä¸‰å¼ å›¾åƒè¿›è¡Œæ‹¼æ¥ [14, 26, 2, 16] å†éšæœºé€‰ä¸‰å¼ å›¾ç‰‡çš„index
        indices = [index] + random.choices(self.indices, k=8)  # 8 additional image indices
        random.shuffle(indices)
        hp, wp = -1, -1  # height, width previous
        for i, index in enumerate(indices):
            # Load image  æ¯æ¬¡æ‹¿ä¸€å¼ å›¾ç‰‡ å¹¶å°†è¿™å¼ å›¾ç‰‡resizeåˆ°self.size(h,w)
            img, _, (h, w) = self.load_image(index)

            # è¿™é‡Œå’Œä¸Šé¢load_mosaicå‡½æ•°çš„æ“ä½œç±»ä¼¼ å°±æ˜¯å°†å–å‡ºçš„imgå›¾ç‰‡åµŒåˆ°img9ä¸­(ä¸æ˜¯çœŸçš„åµŒå…¥ è€Œæ˜¯æ‰¾åˆ°å¯¹åº”çš„ä½ç½®)
            # place img in img9
            if i == 0:  # center
                img9 = np.full((s * 3, s * 3, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
                h0, w0 = h, w
                c = s, s, s + w, s + h  # xmin, ymin, xmax, ymax (base) coordinates
            elif i == 1:  # top
                c = s, s - h, s + w, s
            elif i == 2:  # top right
                c = s + wp, s - h, s + wp + w, s
            elif i == 3:  # right
                c = s + w0, s, s + w0 + w, s + h
            elif i == 4:  # bottom right
                c = s + w0, s + hp, s + w0 + w, s + hp + h
            elif i == 5:  # bottom
                c = s + w0 - w, s + h0, s + w0, s + h0 + h
            elif i == 6:  # bottom left
                c = s + w0 - wp - w, s + h0, s + w0 - wp, s + h0 + h
            elif i == 7:  # left
                c = s - w, s + h0 - h, s, s + h0
            elif i == 8:  # top left
                c = s - w, s + h0 - hp - h, s, s + h0 - hp

            padx, pady = c[:2]
            x1, y1, x2, y2 = (max(x, 0) for x in c)  # allocate coords

            # å’Œä¸Šé¢load_mosaicå‡½æ•°çš„æ“ä½œç±»ä¼¼ æ‰¾åˆ°mosaic9å¢å¼ºåçš„labels9å’Œsegments9
            labels, segments = self.labels[index].copy(), self.segments[index].copy()
            if labels.size:
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padx, pady)  # normalized xywh to pixel xyxy format
                segments = [xyn2xy(x, w, h, padx, pady) for x in segments]
            labels9.append(labels)
            segments9.extend(segments)

            # ç”Ÿæˆå¯¹åº”çš„img9å›¾ç‰‡(å°†å¯¹åº”ä½ç½®çš„å›¾ç‰‡åµŒå…¥img9ä¸­)
            img9[y1:y2, x1:x2] = img[y1 - pady:, x1 - padx:]  # img9[ymin:ymax, xmin:xmax]
            hp, wp = h, w  # height, width previous

        # Offset
        yc, xc = (int(random.uniform(0, s)) for _ in self.mosaic_border)  # mosaic center x, y
        img9 = img9[yc:yc + 2 * s, xc:xc + 2 * s]

        # Concat/clip labels
        labels9 = np.concatenate(labels9, 0)
        labels9[:, [1, 3]] -= xc
        labels9[:, [2, 4]] -= yc
        c = np.array([xc, yc])  # centers
        segments9 = [x - c for x in segments9]

        for x in (labels9[:, 1:], *segments9):
            np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
        # img9, labels9 = replicate(img9, labels9)  # replicate

        # Augment åŒæ ·è¿›è¡Œ éšæœºé€è§†å˜æ¢
        img9, labels9, segments9 = copy_paste(img9, labels9, segments9, p=self.hyp['copy_paste'])
        img9, labels9 = random_perspective(img9,
                                           labels9,
                                           segments9,
                                           degrees=self.hyp['degrees'],
                                           translate=self.hyp['translate'],
                                           scale=self.hyp['scale'],
                                           shear=self.hyp['shear'],
                                           perspective=self.hyp['perspective'],
                                           border=self.mosaic_border)  # border to remove

        return img9, labels9

    @staticmethod
    def collate_fn(batch):
        # æ•´ç†å‡½æ•°,å¦‚ä½•å–æ ·æœ¬,å¯ä»¥å®šä¹‰è‡ªå·±çš„å‡½æ•°æ¥å®ç°æƒ³è¦å®ç°çš„åŠŸèƒ½
        """è¿™ä¸ªå‡½æ•°ä¼šåœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
        æ•´ç†å‡½æ•°  å°†imageå’Œlabelæ•´åˆåˆ°ä¸€èµ·
        :return torch.stack(img, 0): å¦‚[16, 3, 640, 640] æ•´ä¸ªbatchçš„å›¾ç‰‡
        :return torch.cat(label, 0): å¦‚[15, 6] [num_target, img_index+class_index+xywh(normalized)] æ•´ä¸ªbatchçš„label
        :return path: æ•´ä¸ªbatchæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„
        :return shapes: (h0, w0), ((h / h0, w / w0), pad)    for COCO mAP rescaling
        pytorchçš„DataLoaderæ‰“åŒ…ä¸€ä¸ªbatchçš„æ•°æ®é›†æ—¶è¦ç»è¿‡æ­¤å‡½æ•°è¿›è¡Œæ‰“åŒ… é€šè¿‡é‡å†™æ­¤å‡½æ•°å®ç°æ ‡ç­¾ä¸å›¾ç‰‡å¯¹åº”çš„åˆ’åˆ†ï¼Œä¸€ä¸ªbatchä¸­å“ªäº›æ ‡ç­¾å±äºå“ªä¸€å¼ å›¾ç‰‡,å½¢å¦‚
            [[0, 6, 0.5, 0.5, 0.26, 0.35],
             [0, 6, 0.5, 0.5, 0.26, 0.35],
             [1, 6, 0.5, 0.5, 0.26, 0.35],
             [2, 6, 0.5, 0.5, 0.26, 0.35],]
           å‰ä¸¤è¡Œæ ‡ç­¾å±äºç¬¬ä¸€å¼ å›¾ç‰‡, ç¬¬ä¸‰è¡Œå±äºç¬¬äºŒå¼ ã€‚ã€‚ã€‚
        """
        # img: ä¸€ä¸ªtuple ç”±batch_sizeä¸ªtensorç»„æˆ æ•´ä¸ªbatchä¸­æ¯ä¸ªtensorè¡¨ç¤ºä¸€å¼ å›¾ç‰‡
        # label: ä¸€ä¸ªtuple ç”±batch_sizeä¸ªtensorç»„æˆ æ¯ä¸ªtensorå­˜æ”¾ä¸€å¼ å›¾ç‰‡çš„æ‰€æœ‰çš„targetä¿¡æ¯
        #        label[6, object_num] 6ä¸­çš„ç¬¬ä¸€ä¸ªæ•°ä»£è¡¨ä¸€ä¸ªbatchä¸­çš„ç¬¬å‡ å¼ å›¾
        # path: ä¸€ä¸ªtuple ç”±4ä¸ªstrç»„æˆ, æ¯ä¸ªstrå¯¹åº”ä¸€å¼ å›¾ç‰‡çš„åœ°å€ä¿¡æ¯
        im, label, path, shapes = zip(*batch)  # transposed
        for i, lb in enumerate(label):
            lb[:, 0] = i  # add target image index for build_targets()
        # è¿”å›çš„img=[batch_size, 3, 736, 736]
        #      torch.stack(img, 0): å°†batch_sizeä¸ª[3, 736, 736]çš„çŸ©é˜µæ‹¼æˆä¸€ä¸ª[batch_size, 3, 736, 736]
        # label=[target_sums, 6]  6ï¼šè¡¨ç¤ºå½“å‰targetå±äºå“ªä¸€å¼ å›¾+class+x+y+w+h
        #      torch.cat(label, 0): å°†[n1,6]ã€[n2,6]ã€[n3,6]...æ‹¼æ¥æˆ[n1+n2+n3+..., 6]
        # è¿™é‡Œä¹‹æ‰€ä»¥æ‹¼æ¥çš„æ–¹å¼ä¸åŒæ˜¯å› ä¸ºimgæ‹¼æ¥çš„æ—¶å€™å®ƒçš„æ¯ä¸ªéƒ¨åˆ†çš„å½¢çŠ¶æ˜¯ç›¸åŒçš„ï¼Œéƒ½æ˜¯[3, 736, 736]
        # è€Œæˆ‘labelçš„æ¯ä¸ªéƒ¨åˆ†çš„å½¢çŠ¶æ˜¯ä¸ä¸€å®šç›¸åŒçš„ï¼Œæ¯å¼ å›¾çš„ç›®æ ‡ä¸ªæ•°æ˜¯ä¸ä¸€å®šç›¸åŒçš„ï¼ˆlabelè‚¯å®šä¹Ÿå¸Œæœ›ç”¨stack,æ›´æ–¹ä¾¿,ä½†æ˜¯ä¸èƒ½é‚£æ ·æ‹¼ï¼‰
        # å¦‚æœæ¯å¼ å›¾çš„ç›®æ ‡ä¸ªæ•°æ˜¯ç›¸åŒçš„ï¼Œé‚£æˆ‘ä»¬å°±å¯èƒ½ä¸éœ€è¦é‡å†™collate_fnå‡½æ•°äº†
        return torch.stack(im, 0), torch.cat(label, 0), path, shapes

    @staticmethod
    def collate_fn4(batch):
        """åŒæ ·åœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
        è¿™é‡Œæ˜¯yolo-v5ä½œè€…å®éªŒæ€§çš„ä¸€ä¸ªä»£ç  quad-collate function å½“train.pyçš„optå‚æ•°quad=True åˆ™è°ƒç”¨collate_fn4ä»£æ›¿collate_fn
        ä½œç”¨:  å¦‚ä¹‹å‰ç”¨collate_fnå¯ä»¥è¿”å›å›¾ç‰‡[16, 3, 640, 640] ç»è¿‡collate_fn4åˆ™è¿”å›å›¾ç‰‡[4, 3, 1280, 1280]
              å°†4å¼ mosaicå›¾ç‰‡[1, 3, 640, 640]åˆæˆä¸€å¼ å¤§çš„mosaicå›¾ç‰‡[1, 3, 1280, 1280]
              å°†ä¸€ä¸ªbatchçš„å›¾ç‰‡æ¯å››å¼ å¤„ç†, 0.5çš„æ¦‚ç‡å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ, 0.5æ¦‚ç‡ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
        """
        # img: æ•´ä¸ªbatchçš„å›¾ç‰‡ [16, 3, 640, 640]
        # label: æ•´ä¸ªbatchçš„labelæ ‡ç­¾ [num_target, img_index+class_index+xywh(normalized)]
        # path: æ•´ä¸ªbatchæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„
        # shapes: (h0, w0), ((h / h0, w / w0), pad)    for COCO mAP rescaling
        im, label, path, shapes = zip(*batch)  # transposed
        n = len(shapes) // 4  # collate_fn4å¤„ç†åè¿™ä¸ªbatchä¸­å›¾ç‰‡çš„ä¸ªæ•°
        im4, label4, path4, shapes4 = [], [], path[:n], shapes[:n]

        ho = torch.tensor([[0.0, 0, 0, 1, 0, 0]])
        wo = torch.tensor([[0.0, 0, 1, 0, 0, 0]])
        s = torch.tensor([[1, 1, 0.5, 0.5, 0.5, 0.5]])  # scale
        for i in range(n):  # zidane torch.zeros(16,3,720,1280)  # BCHW
            i *= 4  # é‡‡æ · [0, 4, 8, 16]
            if random.random() < 0.5:
                # éšæœºæ•°å°äº0.5å°±ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
                im1 = F.interpolate(im[i].unsqueeze(0).float(), scale_factor=2.0, mode='bilinear',
                                    align_corners=False)[0].type(im[i].type())
                lb = label[i]
            else:
                # éšæœºæ•°å¤§äº0.5å°±å°†å››å¼ å›¾ç‰‡(mosaicåçš„)æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ
                im1 = torch.cat((torch.cat((im[i], im[i + 1]), 1), torch.cat((im[i + 2], im[i + 3]), 1)), 2)
                lb = torch.cat((label[i], label[i + 1] + ho, label[i + 2] + wo, label[i + 3] + ho + wo), 0) * s
            im4.append(im1)
            label4.append(lb)

        # åé¢è¿”å›çš„éƒ¨åˆ†å’Œcollate_fnå°±å·®ä¸å¤šäº† åŸå› å’Œè§£é‡Šéƒ½å†™åœ¨ä¸Šä¸€ä¸ªå‡½æ•°äº† è‡ªå·±debugçœ‹ä¸€ä¸‹å§
        for i, lb in enumerate(label4):
            lb[:, 0] = i  # add target image index for build_targets()

        return torch.stack(im4, 0), torch.cat(label4, 0), path4, shapes4


# Ancillary functions --------------------------------------------------------------------------------------------------
def flatten_recursive(path=DATASETS_DIR / 'coco128'):
    """æ²¡ç”¨åˆ°  ä¸æ˜¯å¾ˆé‡è¦
    å°†ä¸€ä¸ªæ–‡ä»¶è·¯å¾„ä¸­çš„æ‰€æœ‰æ–‡ä»¶å¤åˆ¶åˆ°å¦ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­  å³å°†imageæ–‡ä»¶å’Œlabelæ–‡ä»¶æ”¾åˆ°ä¸€ä¸ªæ–°æ–‡ä»¶å¤¹ä¸­
    Flatten a recursive directory by bringing all files to top level
    """
    # Flatten a recursive directory by bringing all files to top level
    new_path = Path(f'{str(path)}_flat')
    if os.path.exists(new_path):
        shutil.rmtree(new_path)  # delete output folder
    os.makedirs(new_path)  # make new output folder
    for file in tqdm(glob.glob(f'{str(Path(path))}/**/*.*', recursive=True)):
        # shutil.copyfile: å¤åˆ¶æ–‡ä»¶åˆ°å¦ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­
        shutil.copyfile(file, new_path / Path(file).name)


def extract_boxes(path=DATASETS_DIR / 'coco128'):  # from utils.dataloaders import *; extract_boxes()
    """è‡ªè¡Œä½¿ç”¨ ç”Ÿæˆåˆ†ç±»æ•°æ®é›†
    å°†ç›®æ ‡æ£€æµ‹æ•°æ®é›†è½¬åŒ–ä¸ºåˆ†ç±»æ•°æ®é›† é›†ä½“åšæ³•: æŠŠç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸­çš„æ¯ä¸€ä¸ªgtæ‹†è§£å¼€ åˆ†ç±»åˆ«å­˜å‚¨åˆ°å¯¹åº”çš„æ–‡ä»¶å½“ä¸­
    Convert detection dataset into classification dataset, with one directory per class
    ä½¿ç”¨: from utils.datasets import *; extract_boxes()
    :params path: æ•°æ®é›†åœ°å€
    """
    # Convert detection dataset into classification dataset, with one directory per class
    path = Path(path)  # images dir
    shutil.rmtree(path / 'classification') if (path / 'classification').is_dir() else None  # remove existing
    files = list(path.rglob('*.*'))
    n = len(files)  # number of files
    for im_file in tqdm(files, total=n):
        if im_file.suffix[1:] in IMG_FORMATS:
            # image
            im = cv2.imread(str(im_file))[..., ::-1]  # BGR to RGB
            h, w = im.shape[:2]

            # labels æ ¹æ®è¿™å¼ å›¾ç‰‡çš„è·¯å¾„æ‰¾åˆ°è¿™å¼ å›¾ç‰‡çš„labelè·¯å¾„
            lb_file = Path(img2label_paths([str(im_file)])[0])
            if Path(lb_file).exists():
                with open(lb_file) as f:  # è¯»å–labelçš„å„è¡Œ: å¯¹åº”å„ä¸ªgtåæ ‡
                    lb = np.array([x.split() for x in f.read().strip().splitlines()], dtype=np.float32)  # labels

                for j, x in enumerate(lb):  # éå†æ¯ä¸€ä¸ªgt
                    c = int(x[0])  # class
                    # ç”Ÿæˆæ–°'file_name path\classifier\class_index\image_name'
                    # å¦‚: 'F:\yolo_v5\datasets\coco128\images\train2017\classifier\45\train2017_000000000009_0.jpg'
                    f = (path / 'classifier') / f'{c}' / f'{path.stem}_{im_file.stem}_{j}.jpg'  # new filename
                    # f.parent: 'F:\yolo_v5\datasets\coco128\images\train2017\classifier\45'
                    if not f.parent.is_dir():
                        # æ¯ä¸€ä¸ªç±»åˆ«çš„ç¬¬ä¸€å¼ ç…§ç‰‡å­˜è¿›å»ä¹‹å‰ å…ˆåˆ›å»ºå¯¹åº”ç±»çš„æ–‡ä»¶å¤¹
                        f.parent.mkdir(parents=True)

                    b = x[1:] * [w, h, w, h]  # box   normalized to æ­£å¸¸å¤§å°
                    # b[2:] = b[2:].max()   pad: rectangle to square
                    b[2:] = b[2:] * 1.2 + 3  # pad
                    b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(int)

                    # é˜²æ­¢bå‡ºç•Œ clip boxes outside of image
                    b[[0, 2]] = np.clip(b[[0, 2]], 0, w)
                    b[[1, 3]] = np.clip(b[[1, 3]], 0, h)
                    assert cv2.imwrite(str(f), im[b[1]:b[3], b[0]:b[2]]), f'box failure in {f}'


def autosplit(path=DATASETS_DIR / 'coco128/images', weights=(0.9, 0.1, 0.0), annotated_only=False):
    """è‡ªè¡Œä½¿ç”¨ è‡ªè¡Œåˆ’åˆ†æ•°æ®é›†
    è‡ªåŠ¨å°†æ•°æ®é›†åˆ’åˆ†ä¸ºtrain/val/testå¹¶ä¿å­˜ path/autosplit_*.txt files
    Usage: from utils.dataloaders import *; autosplit()
    :params path: æ•°æ®é›†imageä½ç½®
    :params weights: åˆ’åˆ†æƒé‡ é»˜è®¤åˆ†åˆ«æ˜¯(0.9, 0.1, 0.0) å¯¹åº”(train, val, test)
    :params annotated_only: Only use images with an annotated txt file
    """
    path = Path(path)  # images dir
    # è·å–imagesä¸­æ‰€æœ‰çš„å›¾ç‰‡ image files only
    files = sorted(x for x in path.rglob('*.*') if x.suffix[1:].lower() in IMG_FORMATS)  # image files only
    n = len(files)  # number of files
    random.seed(0)  # for reproducibility
    # assign each image to a split æ ¹æ®(train, val, test)æƒé‡åˆ’åˆ†åŸå§‹å›¾ç‰‡æ•°æ®é›†
    # indices: [n]   0, 1, 2   åˆ†åˆ«è¡¨ç¤ºæ•°æ®é›†ä¸­æ¯ä¸€å¼ å›¾ç‰‡å±äºå“ªä¸ªæ•°æ®é›† åˆ†åˆ«å¯¹åº”ç€(train, val, test)
    indices = random.choices([0, 1, 2], weights=weights, k=n)  # assign each image to a split

    txt = ['autosplit_train.txt', 'autosplit_val.txt', 'autosplit_test.txt']  # 3 txt files
    for x in txt:
        if (path.parent / x).exists():
            (path.parent / x).unlink()  # remove existing

    print(f'Autosplitting images from {path}' + ', using *.txt labeled images only' * annotated_only)
    for i, img in tqdm(zip(indices, files), total=n):
        if not annotated_only or Path(img2label_paths([str(img)])[0]).exists():  # check label
            with open(path.parent / txt[i], 'a') as f:
                f.write(f'./{img.relative_to(path.parent).as_posix()}' + '\n')  # add image to txt file


def verify_image_label(args):
    """ç”¨åœ¨cache_labelså‡½æ•°ä¸­
    æ£€æµ‹æ•°æ®é›†ä¸­æ¯å¼ å›¾ç‰‡å’Œæ¯å¼ laeblæ˜¯å¦å®Œå¥½
    å›¾ç‰‡æ–‡ä»¶: å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§
    labelæ–‡ä»¶: æ¯ä¸ªgtå¿…é¡»æ˜¯çŸ©å½¢(æ¯è¡Œéƒ½å¾—æ˜¯5ä¸ªæ•° class+xywh) + æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0 + æ ‡ç­¾åæ ‡xywhæ˜¯å¦å½’ä¸€åŒ– + æ ‡ç­¾ä¸­æ˜¯å¦æœ‰é‡å¤çš„åæ ‡
    :params im_file: æ•°æ®é›†ä¸­ä¸€å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
    :params lb_file: æ•°æ®é›†ä¸­ä¸€å¼ å›¾ç‰‡çš„labelç›¸å¯¹è·¯å¾„
    :params prefix: æ—¥å¿—å¤´éƒ¨ä¿¡æ¯(å½©æ‰“é«˜äº®éƒ¨åˆ†)
    :return im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
    :return l: [gt_num, cls+xywh(normalized)]
               å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ lå°±å­˜å‚¨åŸlabel(å…¨éƒ¨æ˜¯æ­£å¸¸çŸ©å½¢æ ‡ç­¾)
               å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾  lå°±å­˜å‚¨ç»è¿‡segments2boxeså¤„ç†å¥½çš„æ ‡ç­¾(æ­£å¸¸çŸ©å½¢æ ‡ç­¾ä¸å¤„ç† å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºçŸ©å½¢æ ‡ç­¾)
    :return shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
    :return segments: å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å­˜å‚¨None
                      å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å°±æŠŠè¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰labelå­˜å‚¨åˆ°segmentsä¸­(è‹¥å¹²ä¸ªæ­£å¸¸gt è‹¥å¹²ä¸ªå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
    :return nm: number missing å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦ä¸¢å¤±         ä¸¢å¤±=1    å­˜åœ¨=0
    :return nf: number found å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦å­˜åœ¨           å­˜åœ¨=1    ä¸¢å¤±=0
    :return ne: number empty å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦æ˜¯ç©ºçš„         ç©ºçš„=1    æ²¡ç©º=0
    :return nc: number corrupt å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ–‡ä»¶æ˜¯å¦æ˜¯ç ´æŸçš„  ç ´æŸçš„=1  æ²¡ç ´æŸ=0
    :return msg: è¿”å›çš„msgä¿¡æ¯  labelæ–‡ä»¶å®Œå¥½=â€˜â€™  labelæ–‡ä»¶ç ´æŸ=warningä¿¡æ¯
    """
    im_file, lb_file, prefix = args
    nm, nf, ne, nc, msg, segments = 0, 0, 0, 0, '', []  # number (missing, found, empty, corrupt), message, segments
    try:
        # æ£€æŸ¥è¿™å¼ å›¾ç‰‡(å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§) verify images
        im = Image.open(im_file)  # æ‰“å¼€å›¾ç‰‡æ–‡ä»¶
        im.verify()  # PIL verify æ£€æŸ¥å›¾ç‰‡å†…å®¹å’Œæ ¼å¼æ˜¯å¦æ­£å¸¸
        shape = exif_size(im)  # å½“å‰å›¾ç‰‡çš„å¤§å° image size
        assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'  # å›¾ç‰‡å¤§å°å¿…é¡»å¤§äº9ä¸ªpixels
        assert im.format.lower() in IMG_FORMATS, f'invalid image format {im.format}'  # å›¾ç‰‡æ ¼å¼å¿…é¡»åœ¨img_formatä¸­
        if im.format.lower() in ('jpg', 'jpeg'):  # æ£€æŸ¥jpgæ ¼å¼æ–‡ä»¶
            with open(im_file, 'rb') as f:
                # f.seek: -2 åç§»é‡ å‘æ–‡ä»¶å¤´æ–¹å‘ä¸­ç§»åŠ¨çš„å­—èŠ‚æ•°   2 ç›¸å¯¹ä½ç½® ä»æ–‡ä»¶å°¾å¼€å§‹åç§»
                f.seek(-2, 2)
                # f.read(): è¯»å–å›¾ç‰‡æ–‡ä»¶  æŒ‡ä»¤: \xff\xd9  æ£€æµ‹æ•´å¼ å›¾ç‰‡æ˜¯å¦å®Œæ•´  å¦‚æœä¸å®Œæ•´å°±è¿”å›corrupted JPEG
                if f.read() != b'\xff\xd9':  # corrupt JPEG
                    ImageOps.exif_transpose(Image.open(im_file)).save(im_file, 'JPEG', subsampling=0, quality=100)
                    msg = f'{prefix}WARNING âš ï¸ {im_file}: corrupt JPEG restored and saved'

        # verify labels
        if os.path.isfile(lb_file):
            nf = 1  # label found
            with open(lb_file) as f:
                # è¯»å–å½“å‰labelæ–‡ä»¶çš„æ¯ä¸€è¡Œ: æ¯ä¸€è¡Œéƒ½æ˜¯å½“å‰å›¾ç‰‡çš„ä¸€ä¸ªgt
                lb = [x.split() for x in f.read().strip().splitlines() if len(x)]
                # any() å‡½æ•°ç”¨äºåˆ¤æ–­ç»™å®šçš„å¯è¿­ä»£å‚æ•° æ˜¯å¦å…¨éƒ¨ä¸ºFalse,åˆ™è¿”å› False; å¦‚æœæœ‰ä¸€ä¸ªä¸º True,åˆ™è¿”å›True
                # å¦‚æœå½“å‰å›¾ç‰‡çš„labelæ–‡ä»¶æŸä¸€åˆ—æ•°å¤§äº8, åˆ™è®¤ä¸ºlabelæ˜¯å­˜åœ¨segmentçš„polygonç‚¹(å¤šè¾¹å½¢)  å°±ä¸æ˜¯çŸ©é˜µ åˆ™å°†labelä¿¡æ¯å­˜å…¥segmentä¸­
                if any(len(x) > 6 for x in lb):  # is segment
                    # å½“å‰å›¾ç‰‡ä¸­æ‰€æœ‰gtæ¡†çš„ç±»åˆ«
                    classes = np.array([x[0] for x in lb], dtype=np.float32)
                    # è·å¾—è¿™å¼ å›¾ä¸­æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾)
                    # å› ä¸ºsegmentæ ‡ç­¾å¯ä»¥æ˜¯ä¸åŒé•¿åº¦ï¼Œæ‰€ä»¥è¿™é‡Œsegmentsæ˜¯ä¸€ä¸ªåˆ—è¡¨ [gt_num, xy1...(normalized)]
                    segments = [np.array(x[1:], dtype=np.float32).reshape(-1, 2) for x in lb]  # (cls, xy1...)
                    # è·å¾—è¿™å¼ å›¾ä¸­æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(ä¸åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾)
                    # segments(å¤šè¾¹å½¢) -> bbox(æ­£æ–¹å½¢), å¾—åˆ°æ–°æ ‡ç­¾  [gt_num, cls+xywh(normalized)]
                    lb = np.concatenate((classes.reshape(-1, 1), segments2boxes(segments)), 1)  # (cls, xywh)
                lb = np.array(lb, dtype=np.float32)
            nl = len(lb)
            if nl:
                # åˆ¤æ–­æ ‡ç­¾æ˜¯å¦æœ‰äº”åˆ—
                assert lb.shape[1] == 5, f'labels require 5 columns, {lb.shape[1]} columns detected'
                # åˆ¤æ–­æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0
                assert (lb >= 0).all(), f'negative label values {lb[lb < 0]}'
                # åˆ¤æ–­æ ‡ç­¾åæ ‡x y w hæ˜¯å¦å½’ä¸€åŒ–
                assert (lb[:, 1:] <= 1).all(), f'non-normalized or out of bounds coordinates {lb[:, 1:][lb[:, 1:] > 1]}'
                _, i = np.unique(lb, axis=0, return_index=True)
                if len(i) < nl:  # duplicate row check
                    lb = lb[i]  # remove duplicates
                    if segments:
                        segments = [segments[x] for x in i]
                    msg = f'{prefix}WARNING âš ï¸ {im_file}: {nl - len(i)} duplicate labels removed'
            else:
                ne = 1  # label empty
                lb = np.zeros((0, 5), dtype=np.float32)
        else:
            nm = 1  # label missing
            lb = np.zeros((0, 5), dtype=np.float32)
        return im_file, lb, shape, segments, nm, nf, ne, nc, msg
    except Exception as e:
        nc = 1
        msg = f'{prefix}WARNING âš ï¸ {im_file}: ignoring corrupt image/label: {e}'
        return [None, None, None, None, nm, nf, ne, nc, msg]


class HUBDatasetStats():
    """ Class for generating HUB dataset JSON and `-hub` dataset directory

    Arguments
        path:           Path to data.yaml or data.zip (with data.yaml inside data.zip)
        autodownload:   Attempt to download dataset if not found locally

    Usage
        from utils.dataloaders import HUBDatasetStats
        stats = HUBDatasetStats('coco128.yaml', autodownload=True)  # usage 1
        stats = HUBDatasetStats('path/to/coco128.zip')  # usage 2
        stats.get_json(save=False)
        stats.process_images()
    """

    def __init__(self, path='coco128.yaml', autodownload=False):
        # Initialize class
        zipped, data_dir, yaml_path = self._unzip(Path(path))
        try:
            with open(check_yaml(yaml_path), errors='ignore') as f:
                data = yaml.safe_load(f)  # data dict
                if zipped:
                    data['path'] = data_dir
        except Exception as e:
            raise Exception('error/HUB/dataset_stats/yaml_load') from e

        check_dataset(data, autodownload)  # download dataset if missing
        self.hub_dir = Path(data['path'] + '-hub')
        self.im_dir = self.hub_dir / 'images'
        self.im_dir.mkdir(parents=True, exist_ok=True)  # makes /images
        self.stats = {'nc': data['nc'], 'names': list(data['names'].values())}  # statistics dictionary
        self.data = data

    @staticmethod
    def _find_yaml(dir):
        # Return data.yaml file
        files = list(dir.glob('*.yaml')) or list(dir.rglob('*.yaml'))  # try root level first and then recursive
        assert files, f'No *.yaml file found in {dir}'
        if len(files) > 1:
            files = [f for f in files if f.stem == dir.stem]  # prefer *.yaml files that match dir name
            assert files, f'Multiple *.yaml files found in {dir}, only 1 *.yaml file allowed'
        assert len(files) == 1, f'Multiple *.yaml files found: {files}, only 1 *.yaml file allowed in {dir}'
        return files[0]

    def _unzip(self, path):
        # Unzip data.zip
        if not str(path).endswith('.zip'):  # path is data.yaml
            return False, None, path
        assert Path(path).is_file(), f'Error unzipping {path}, file not found'
        unzip_file(path, path=path.parent)
        dir = path.with_suffix('')  # dataset directory == zip name
        assert dir.is_dir(), f'Error unzipping {path}, {dir} not found. path/to/abc.zip MUST unzip to path/to/abc/'
        return True, str(dir), self._find_yaml(dir)  # zipped, data_dir, yaml_path

    def _hub_ops(self, f, max_dim=1920):
        # HUB ops for 1 image 'f': resize and save at reduced quality in /dataset-hub for web/app viewing
        f_new = self.im_dir / Path(f).name  # dataset-hub image filename
        try:  # use PIL
            im = Image.open(f)
            r = max_dim / max(im.height, im.width)  # ratio
            if r < 1.0:  # image too large
                im = im.resize((int(im.width * r), int(im.height * r)))
            im.save(f_new, 'JPEG', quality=50, optimize=True)  # save
        except Exception as e:  # use OpenCV
            LOGGER.info(f'WARNING âš ï¸ HUB ops PIL failure {f}: {e}')
            im = cv2.imread(f)
            im_height, im_width = im.shape[:2]
            r = max_dim / max(im_height, im_width)  # ratio
            if r < 1.0:  # image too large
                im = cv2.resize(im, (int(im_width * r), int(im_height * r)), interpolation=cv2.INTER_AREA)
            cv2.imwrite(str(f_new), im)

    def get_json(self, save=False, verbose=False):
        # Return dataset JSON for Ultralytics HUB
        def _round(labels):
            # Update labels to integer class and 6 decimal place floats
            return [[int(c), *(round(x, 4) for x in points)] for c, *points in labels]

        for split in 'train', 'val', 'test':
            if self.data.get(split) is None:
                self.stats[split] = None  # i.e. no test set
                continue
            dataset = LoadImagesAndLabels(self.data[split])  # load dataset
            x = np.array([
                np.bincount(label[:, 0].astype(int), minlength=self.data['nc'])
                for label in tqdm(dataset.labels, total=dataset.n, desc='Statistics')])  # shape(128x80)
            # åˆ†åˆ«ç»Ÿè®¡trainã€valã€testä¸‰ä¸ªæ•°æ®é›†çš„æ•°æ®ä¿¡æ¯
            # åŒ…æ‹¬: 'image_stats': å­—å…¸dict  å›¾ç‰‡æ•°é‡total  æ²¡æœ‰æ ‡ç­¾çš„æ–‡ä»¶ä¸ªæ•°unlabelled  æ•°æ®é›†æ¯ä¸ªç±»åˆ«çš„gtä¸ªæ•°[80]
            # 'instance_stats': å­—å…¸dict  æ•°æ®é›†ä¸­æ‰€æœ‰å›¾ç‰‡çš„æ‰€æœ‰gtä¸ªæ•°total   æ•°æ®é›†ä¸­æ¯ä¸ªç±»åˆ«çš„gtä¸ªæ•°[80]
            # 'labels': å­—å…¸dict  key=æ•°æ®é›†ä¸­æ¯å¼ å›¾ç‰‡çš„æ–‡ä»¶å  value=æ¯å¼ å›¾ç‰‡å¯¹åº”çš„labelä¿¡æ¯ [n, cls+xywh]
            self.stats[split] = {
                'instance_stats': {
                    'total': int(x.sum()),
                    'per_class': x.sum(0).tolist()},
                'image_stats': {
                    'total': dataset.n,
                    'unlabelled': int(np.all(x == 0, 1).sum()),
                    'per_class': (x > 0).sum(0).tolist()},
                'labels': [{
                    str(Path(k).name): _round(v.tolist())} for k, v in zip(dataset.im_files, dataset.labels)]}

        # Save, print and return
        if save:
            stats_path = self.hub_dir / 'stats.json'
            print(f'Saving {stats_path.resolve()}...')
            with open(stats_path, 'w') as f:
                json.dump(self.stats, f)  # save stats.json
        if verbose:
            print(json.dumps(self.stats, indent=2, sort_keys=False))
        return self.stats

    def process_images(self):
        # Compress images for Ultralytics HUB
        for split in 'train', 'val', 'test':
            if self.data.get(split) is None:
                continue
            dataset = LoadImagesAndLabels(self.data[split])  # load dataset
            desc = f'{split} images'
            for _ in tqdm(ThreadPool(NUM_THREADS).imap(self._hub_ops, dataset.im_files), total=dataset.n, desc=desc):
                pass
        print(f'Done. All images saved to {self.im_dir}')
        return self.im_dir


# Classification dataloaders -------------------------------------------------------------------------------------------
class ClassificationDataset(torchvision.datasets.ImageFolder):
    """
    YOLOv5 Classification Dataset.
    Arguments
        root:  Dataset path
        transform:  torchvision transforms, used by default
        album_transform: Albumentations transforms, used if installed
    """

    def __init__(self, root, augment, imgsz, cache=False):
        super().__init__(root=root)
        self.torch_transforms = classify_transforms(imgsz)
        self.album_transforms = classify_albumentations(augment, imgsz) if augment else None
        self.cache_ram = cache is True or cache == 'ram'
        self.cache_disk = cache == 'disk'
        self.samples = [list(x) + [Path(x[0]).with_suffix('.npy'), None] for x in self.samples]  # file, index, npy, im

    def __getitem__(self, i):
        f, j, fn, im = self.samples[i]  # filename, index, filename.with_suffix('.npy'), image
        if self.cache_ram and im is None:
            im = self.samples[i][3] = cv2.imread(f)
        elif self.cache_disk:
            if not fn.exists():  # load npy
                np.save(fn.as_posix(), cv2.imread(f))
            im = np.load(fn)
        else:  # read image
            im = cv2.imread(f)  # BGR
        if self.album_transforms:
            sample = self.album_transforms(image=cv2.cvtColor(im, cv2.COLOR_BGR2RGB))['image']
        else:
            sample = self.torch_transforms(im)
        return sample, j


def create_classification_dataloader(path,
                                     imgsz=224,
                                     batch_size=16,
                                     augment=True,
                                     cache=False,
                                     rank=-1,
                                     workers=8,
                                     shuffle=True):
    # Returns Dataloader object to be used with YOLOv5 Classifier
    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP
        dataset = ClassificationDataset(root=path, imgsz=imgsz, augment=augment, cache=cache)
    batch_size = min(batch_size, len(dataset))
    nd = torch.cuda.device_count()
    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    generator = torch.Generator()
    generator.manual_seed(6148914691236517205 + RANK)
    return InfiniteDataLoader(dataset,
                              batch_size=batch_size,
                              shuffle=shuffle and sampler is None,
                              num_workers=nw,
                              sampler=sampler,
                              pin_memory=PIN_MEMORY,
                              worker_init_fn=seed_worker,
                              generator=generator)  # or DataLoader(persistent_workers=True)
